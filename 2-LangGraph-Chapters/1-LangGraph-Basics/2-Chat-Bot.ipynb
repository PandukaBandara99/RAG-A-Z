{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementing simple Chatbot Using LangGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TypedDict for defining structured types (dictionaries with fixed key-value types)\n",
    "# This helps to define state or configuration objects with strict typing.\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Import the StateGraph, START, and END from LangGraph.\n",
    "# - StateGraph: The main class used to create and manage graph-based workflows.\n",
    "# - START and END: Special nodes representing the entry and exit points of a workflow.\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "## Reducers\n",
    "# Reducers are typically functions used in LangGraph (and similar frameworks)\n",
    "# to manage state updates between nodes, combining multiple pieces of state or data.\n",
    "\n",
    "# Importing Annotated for type hinting with metadata (like specifying constraints or descriptions)\n",
    "# Annotated allows adding extra context to type hints beyond just the type itself.\n",
    "from typing import Annotated\n",
    "\n",
    "# Importing add_messages from LangGraph's message utilities.\n",
    "# This helper function is used to merge or append message lists in conversational graph states.\n",
    "# It helps in handling multi-turn conversations by accumulating message history.\n",
    "from langgraph.graph.message import add_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom type 'State' using TypedDict.\n",
    "# TypedDict allows you to create dictionary-like structures with type-checked keys.\n",
    "# Each key in this dictionary has a defined expected type.\n",
    "\n",
    "class State(TypedDict):\n",
    "    # 'messages' key will store a list of messages (e.g., conversation history or model interactions).\n",
    "    # The type hint `Annotated[list, add_messages]` means:\n",
    "    #   - The base type is a list (likely containing message objects or strings).\n",
    "    #   - The `add_messages` function is annotated as a reducer — it defines *how* to combine or update this list\n",
    "    #     when the state is updated (for example, appending new messages rather than overwriting them).\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'os' module to interact with the operating system.\n",
    "# It allows access to environment variables, file paths, and system configurations.\n",
    "import os\n",
    "\n",
    "# Import 'load_dotenv' from the 'dotenv' package.\n",
    "# This function loads environment variables from a '.env' file into the system's environment.\n",
    "# It's commonly used to keep API keys and sensitive credentials outside of the source code.\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load all environment variables defined in the '.env' file into the current runtime environment.\n",
    "# After calling this, you can access variables in the file using 'os.getenv(\"VAR_NAME\")'.\n",
    "load_dotenv()\n",
    "\n",
    "# Explicitly set the \"OPENAI_API_KEY\" environment variable.\n",
    "# It retrieves the key from the loaded environment (via .env file) and assigns it to the OS environment.\n",
    "# This ensures other libraries or frameworks can access the key globally.\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Similarly, set the \"GROQ_API_KEY\" environment variable.\n",
    "# This makes sure the Groq API key is also available globally through the environment.\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-902c91c5-ea3a-4466-a6c3-fea75daf2ca0-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the ChatOpenAI class from the 'langchain_openai' package.\n",
    "# This class provides a convenient interface to interact with OpenAI’s chat models (e.g., GPT-4, GPT-4o).\n",
    "# It handles API calls, message formatting, and response parsing automatically.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create an instance of the ChatOpenAI class and assign it to the variable 'llm'.\n",
    "# - The 'model' parameter specifies which OpenAI model to use.\n",
    "# - Here, \"gpt-4o\" refers to the GPT-4 Omni model, which supports both text and vision inputs.\n",
    "# The 'llm' variable now represents a language model object ready to process chat-style prompts.\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Invoke the language model with a simple text prompt.\n",
    "# The 'invoke()' method sends the input (\"Hello\") to the model and returns its response.\n",
    "# This is equivalent to having a one-turn conversation with the LLM.\n",
    "llm.invoke(\"Hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Krish! That's great to hear that you enjoy playing cricket. Cricket is a fantastic sport that requires skill, strategy, and teamwork. Whether you play as a batsman, bowler, or fielder, each role offers unique challenges and excitement.\\n\\nIf you have any questions about cricket, tips on how to improve your game, or anything else cricket-related, feel free to ask!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 39, 'total_tokens': 118, 'completion_time': 0.395, 'prompt_time': 0.004205269, 'queue_time': 0.225996294, 'total_time': 0.399205269}, 'model_name': 'qwen-2.5-32b', 'system_fingerprint': 'fp_35f92f8282', 'finish_reason': 'stop', 'logprobs': None}, id='run-9bbe32ce-bcac-4f94-97fb-7d0c1d61690c-0', usage_metadata={'input_tokens': 39, 'output_tokens': 79, 'total_tokens': 118})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_groq=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "llm_groq.invoke(\"Hey I am Krish and i like to play cricket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **We Will start With Creating Nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function named 'superbot' that takes one argument: 'state'.\n",
    "# The 'state' parameter follows the structure defined earlier by the 'State' TypedDict.\n",
    "# It is expected to contain a key 'messages' that holds a list of conversation messages.\n",
    "def superbot(state: State):\n",
    "    # The function returns a new dictionary with a single key 'messages'.\n",
    "    # Inside it, we invoke the Groq model ('llm_groq') using the current state's messages as input.\n",
    "    # - 'state[\"messages\"]' retrieves the conversation history or latest message(s).\n",
    "    # - 'llm_groq.invoke(...)' sends this data to the Groq model for generating a response.\n",
    "    # The response is wrapped in a list so that it matches the structure expected by LangGraph states.\n",
    "    return {\"messages\": [llm_groq.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph=StateGraph(State)\n",
    "\n",
    "## node\n",
    "graph.add_node(\"SuperBot\",superbot)\n",
    "## Edges\n",
    "\n",
    "graph.add_edge(START,\"SuperBot\")\n",
    "graph.add_edge(\"SuperBot\",END)\n",
    "\n",
    "\n",
    "graph_builder=graph.compile()\n",
    "\n",
    "\n",
    "## Display\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi,My name is Krish And I like cricket', additional_kwargs={}, response_metadata={}, id='a28ca34c-eada-478e-8ed8-ef3759447093'),\n",
       "  AIMessage(content=\"Hello Krish! Nice to meet you. Cricket is a fantastic sport, isn't it? Do you enjoy playing cricket or are you more into watching the matches? Who is your favorite cricket player? Feel free to share more about what you like about the sport!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 39, 'total_tokens': 92, 'completion_time': 0.265, 'prompt_time': 0.004223914, 'queue_time': 0.236344133, 'total_time': 0.269223914}, 'model_name': 'qwen-2.5-32b', 'system_fingerprint': 'fp_35f92f8282', 'finish_reason': 'stop', 'logprobs': None}, id='run-a20669ad-74bd-440e-96f1-e368a5a9cdce-0', usage_metadata={'input_tokens': 39, 'output_tokens': 53, 'total_tokens': 92})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Invocation\n",
    "graph_builder.invoke({'messages':\"Hi,My name is Krish And I like cricket\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming The responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SuperBot': {'messages': [AIMessage(content=\"Hello Krish! It's nice to meet you. How can I assist you today? Is there anything specific you would like to talk about or any questions you have?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 35, 'total_tokens': 69, 'completion_time': 0.17, 'prompt_time': 0.003981866, 'queue_time': 0.226247007, 'total_time': 0.173981866}, 'model_name': 'qwen-2.5-32b', 'system_fingerprint': 'fp_35f92f8282', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb7964d1-a9df-477e-b016-539ee446c375-0', usage_metadata={'input_tokens': 35, 'output_tokens': 34, 'total_tokens': 69})]}}\n"
     ]
    }
   ],
   "source": [
    "for event in graph_builder.stream({\"messages\":\"Hello My name is KRish\"}):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding `TypedDict` in LangGraph**\n",
    "\n",
    "In LangGraph, **`TypedDict`** is used to **define the structure of the state** — the shared memory or message context that passes between nodes.\n",
    "It gives **type safety**, **clarity**, and **predictable state transitions** in complex workflows.\n",
    "\n",
    "**Concept\n",
    "**\n",
    "A **LangGraph State** is like a message or memory container shared across the graph.\n",
    "Every node reads from it, processes information, and updates it for downstream nodes.\n",
    "\n",
    "```python\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Define the state of the chatbot conversation\n",
    "class ChatState(TypedDict):\n",
    "    user_messages: List[str]\n",
    "    ai_responses: List[str]\n",
    "    context: str\n",
    "```\n",
    "\n",
    "This `ChatState` defines **what data the chatbot will track**:\n",
    "\n",
    "* `user_messages`: all inputs from the user\n",
    "* `ai_responses`: model-generated messages\n",
    "* `context`: short-term memory or session context\n",
    "\n",
    "This acts like a **schema** for the chatbot’s memory.\n",
    "\n",
    "---\n",
    "**How `TypedDict` Helps in Chatbots**\n",
    "\n",
    "When building chatbots using **LangGraph**, each node can:\n",
    "\n",
    "* **Access** parts of the state (like the last message),\n",
    "* **Append** new messages,\n",
    "* **Return** updated parts of the state.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "def user_input_node(state: ChatState):\n",
    "    user_text = state[\"user_messages\"][-1]\n",
    "    return {\"context\": f\"User asked: {user_text}\"}\n",
    "```\n",
    "\n",
    "```python\n",
    "def llm_response_node(state: ChatState):\n",
    "    # simulate model inference\n",
    "    ai_reply = f\"AI response to: {state['context']}\"\n",
    "    return {\"ai_responses\": state[\"ai_responses\"] + [ai_reply]}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**What Are Reducers in LangGraph?**\n",
    "\n",
    "Reducers are **functions that merge or combine** outputs from multiple nodes into a **single consistent state**.\n",
    "\n",
    "Imagine multiple nodes (LLMs, tools, retrievers, or filters) updating the same key in the state — LangGraph uses **reducers** to decide how these updates should merge.\n",
    "\n",
    "---\n",
    "\n",
    "**Example Scenario**\n",
    "\n",
    "Suppose we have two nodes:\n",
    "\n",
    "* `SentimentAnalyzer` adds emotional tone.\n",
    "* `KnowledgeRetriever` adds factual context.\n",
    "\n",
    "Both might update `context` in the chatbot state.\n",
    "\n",
    "By default, LangGraph merges these outputs using reducers you define.\n",
    "\n",
    "---\n",
    "\n",
    "**Reducer Example**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "def merge_contexts(old: str, new: str) -> str:\n",
    "    \"\"\"Reducer merges multiple context updates\"\"\"\n",
    "    return old + \" | \" + new\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"Sentiment\", lambda s: {\"context\": \"Sentiment: positive\"})\n",
    "graph.add_node(\"Retriever\", lambda s: {\"context\": \"Context: AI concepts\"})\n",
    "\n",
    "graph.add_edge(\"Sentiment\", \"Retriever\")\n",
    "graph.set_entry_point(\"Sentiment\")\n",
    "\n",
    "# Register reducer for merging context fields\n",
    "graph.add_reducer(\"context\", merge_contexts)\n",
    "```\n",
    "\n",
    "Now, when both nodes update `context`, LangGraph automatically merges them using `merge_contexts()`:\n",
    "\n",
    "```\n",
    "\"Sentiment: positive | Context: AI concepts\"\n",
    "```\n",
    "\n",
    "Without reducers, later nodes might **overwrite** earlier ones — reducers ensure **non-destructive updates**.\n",
    "\n",
    "---\n",
    "\n",
    "**Reducers in Chatbot Context**\n",
    "\n",
    "In chatbots, reducers are useful when multiple agents or reasoning nodes generate updates:\n",
    "\n",
    "* **Multiple LLM agents** proposing responses\n",
    "* **Context expansion nodes** adding retrieved info\n",
    "* **Memory nodes** maintaining conversation history\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "def merge_messages(old, new):\n",
    "    return old + new  # append new messages\n",
    "\n",
    "graph.add_reducer(\"ai_responses\", merge_messages)\n",
    "graph.add_reducer(\"user_messages\", merge_messages)\n",
    "```\n",
    "\n",
    "Now, your chatbot can process **parallel updates** without losing earlier messages.\n",
    "\n",
    "---\n",
    "\n",
    "**Putting It All Together**\n",
    "\n",
    "Here’s a small working LangGraph chatbot:\n",
    "\n",
    "```python\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define chatbot state\n",
    "class ChatState(TypedDict):\n",
    "    user_messages: List[str]\n",
    "    ai_responses: List[str]\n",
    "    context: str\n",
    "\n",
    "# Define nodes\n",
    "def user_node(state: ChatState):\n",
    "    user_text = state[\"user_messages\"][-1]\n",
    "    return {\"context\": f\"User said: {user_text}\"}\n",
    "\n",
    "def llm_node(state: ChatState):\n",
    "    response = f\"Got it! You said '{state['context']}'.\"\n",
    "    return {\"ai_responses\": state[\"ai_responses\"] + [response]}\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"UserInput\", user_node)\n",
    "graph.add_node(\"AIResponse\", llm_node)\n",
    "graph.add_edge(\"UserInput\", \"AIResponse\")\n",
    "graph.add_edge(\"AIResponse\", END)\n",
    "graph.set_entry_point(\"UserInput\")\n",
    "\n",
    "# Add reducers\n",
    "graph.add_reducer(\"ai_responses\", lambda old, new: old + new)\n",
    "graph.add_reducer(\"user_messages\", lambda old, new: old + new)\n",
    "\n",
    "# Compile and run\n",
    "chat = graph.compile()\n",
    "result = chat.invoke({\"user_messages\": [\"Hello!\"], \"ai_responses\": [], \"context\": \"\"})\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```python\n",
    "{\n",
    "  'user_messages': ['Hello!'],\n",
    "  'ai_responses': [\"Got it! You said 'User said: Hello!'. \"],\n",
    "  'context': 'User said: Hello!'\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Concept           | Purpose                             | Example Use in Chatbot                            |\n",
    "| ----------------- | ----------------------------------- | ------------------------------------------------- |\n",
    "| **`TypedDict`**   | Defines the schema for shared state | Tracks messages, memory, context                  |\n",
    "| **Reducers**      | Merge updates from multiple nodes   | Combine multi-agent responses, memory, or context |\n",
    "| **StateGraph**    | Orchestrates nodes and flows        | Controls chatbot reasoning steps                  |\n",
    "| **State Passing** | Maintains continuity                | Enables memory and contextual responses           |\n",
    "\n",
    "---\n",
    "\n",
    " **In essence**\n",
    "\n",
    "* `TypedDict` gives **structure** and **type clarity** to your chatbot’s memory.\n",
    "* **Reducers** enable **intelligent merging** of updates from multiple reasoning or generation nodes.\n",
    "* Combined, they make **LangGraph chatbots modular, context-aware, and scalable** — perfect for complex, multi-step conversational agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
