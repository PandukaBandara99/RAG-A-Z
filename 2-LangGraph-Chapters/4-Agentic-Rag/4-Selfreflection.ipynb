{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3679b0",
   "metadata": {},
   "source": [
    "## **What is Self-Reflection in RAG?**\n",
    "Self-reflection = LLM evaluates its own output:\n",
    "“Is this clear, complete, and accurate?”\n",
    "\n",
    "**Self-Reflection in RAG using LangGraph, we’ll design a workflow where the agent:**\n",
    "\n",
    "1. Generates an initial answer using retrieved context\n",
    "2. Reflects on that answer with a dedicated self-critic LLM step\n",
    "3. If unsatisfied, it can revise the query, retrieve again, or regenerate the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f3ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf072a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load llm models\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "llm=init_chat_model(\"openai:gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc7a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = TextLoader(\"internal_docs.txt\").load()\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50).split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2246d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2. State Definition\n",
    "# -------------------------\n",
    "class RAGReflectionState(BaseModel):\n",
    "    question: str\n",
    "    retrieved_docs: List[Document] = []\n",
    "    answer: str = \"\"\n",
    "    reflection: str = \"\"\n",
    "    revised: bool = False\n",
    "    attempts: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a454cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 3. Nodes\n",
    "# -------------------------\n",
    "\n",
    "# a. Retrieve\n",
    "def retrieve_docs(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    docs = retriever.invoke(state.question)\n",
    "    return state.model_copy(update={\"retrieved_docs\": docs})\n",
    "\n",
    "# b. Generate Answer\n",
    "def generate_answer(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt = f\"\"\"\n",
    "Use the following context to answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{state.question}\n",
    "\"\"\"\n",
    "    answer = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"answer\": answer, \"attempts\": state.attempts + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de27da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Self-Reflect\n",
    "def reflect_on_answer(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Reflect on the following answer to see if it fully addresses the question. \n",
    "State YES if it is complete and correct, or NO with an explanation.\n",
    "\n",
    "Question: {state.question}\n",
    "\n",
    "Answer: {state.answer}\n",
    "\n",
    "Respond like:\n",
    "Reflection: YES or NO\n",
    "Explanation: ...\n",
    "\"\"\"\n",
    "    result = llm.invoke(prompt).content\n",
    "    is_ok = \"reflection: yes\" in result.lower()\n",
    "    return state.model_copy(update={\"reflection\": result, \"revised\": not is_ok})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a07cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Finalizer\n",
    "def finalize(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eafcf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4. LangGraph DAG\n",
    "# -------------------------\n",
    "builder = StateGraph(RAGReflectionState)\n",
    "\n",
    "builder.add_node(\"retriever\", retrieve_docs)\n",
    "builder.add_node(\"responder\", generate_answer)\n",
    "builder.add_node(\"reflector\", reflect_on_answer)\n",
    "builder.add_node(\"done\", finalize)\n",
    "\n",
    "builder.set_entry_point(\"retriever\")\n",
    "\n",
    "builder.add_edge(\"retriever\", \"responder\")\n",
    "builder.add_edge(\"responder\", \"reflector\")\n",
    "builder.add_conditional_edges(\n",
    "    \"reflector\",\n",
    "    lambda s: \"done\" if not s.revised or s.attempts >= 2 else \"retriever\"\n",
    ")\n",
    "\n",
    "builder.add_edge(\"done\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3ed5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Final Answer:\n",
      " The transformer variants mentioned in the production deployments are:\n",
      "\n",
      "1. EfficientFormer\n",
      "3. Reformer\n",
      "4. LLaMA2\n",
      "5. TinyBERT\n",
      "\n",
      "🔁 Reflection Log:\n",
      " Reflection: NO  \n",
      "Explanation: While the answer lists some transformer variants such as EfficientFormer, Reformer, LLaMA2, and TinyBERT, it is incomplete. There are numerous other transformer variants widely used in production deployments that are not mentioned, such as BERT, GPT-3, DistilBERT, RoBERTa, and T5. The answer should include a broader range of examples to fully address the question. Additionally, it should provide some context or explanation for why these specific variants are notable in the context of production usage.\n",
      "🔄 Total Attempts: 2\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 5. Run the Agent\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"What are the transformer variants in production deployments?\"\n",
    "    init_state = RAGReflectionState(question=user_query)\n",
    "    result = graph.invoke(init_state)\n",
    "\n",
    "    print(\"\\n🧠 Final Answer:\\n\", result[\"answer\"])\n",
    "    print(\"\\n🔁 Reflection Log:\\n\", result[\"reflection\"])\n",
    "    print(\"🔄 Total Attempts:\", result[\"attempts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f8cec2",
   "metadata": {},
   "source": [
    "##  **Self-Reflection with RAGs and ReAct Agents in LangGraph & LangChain**\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Idea\n",
    "\n",
    "In advanced AI systems, we want agents that can:\n",
    "\n",
    "* **Retrieve** real data (RAG).\n",
    "* **Reason** and make decisions (ReAct).\n",
    "* **Reflect** on their own output and **self-correct** (Self-Reflection).\n",
    "\n",
    "So, the agent doesn’t just generate answers — it:\n",
    "\n",
    "> 💭 *Thinks → Acts → Evaluates → Improves → Responds.*\n",
    "\n",
    "This forms a **self-improving reasoning loop** — and LangGraph + LangChain give you the tools to implement this *elegantly.*\n",
    "\n",
    "---\n",
    "\n",
    "## The Three Pillars\n",
    "\n",
    "| Concept                                     | Description                                                                                          | Analogy                           |\n",
    "| ------------------------------------------- | ---------------------------------------------------------------------------------------------------- | --------------------------------- |\n",
    "| 🧩 **RAG (Retrieval-Augmented Generation)** | Brings **facts** by retrieving relevant context from external data sources                           | “Looking it up in your notes”     |\n",
    "| 🧠 **ReAct Agent**                          | Combines **Reasoning + Action** — LLM decides when to think, when to use a tool, and when to respond | “Thinking + Doing”                |\n",
    "| 🔁 **Self-Reflection**                      | Model **reviews its own output**, identifies flaws, and improves before finalizing                   | “Proofreading your own reasoning” |\n",
    "\n",
    "Together, these make your agent **smart, grounded, and self-improving.**\n",
    "\n",
    "---\n",
    "\n",
    "## Concept Flow\n",
    "\n",
    "Let’s visualize the **Self-Reflective RAG ReAct Loop**:\n",
    "\n",
    "```\n",
    "User Query\n",
    "   ↓\n",
    "[Retriever] → Get Context\n",
    "   ↓\n",
    "[Reasoning (ReAct)] → Think + Take Actions\n",
    "   ↓\n",
    "[Reflection] → Review Output, Check for Hallucination or Gaps\n",
    "   ↓\n",
    "[Refine / Retry] → Generate Improved Final Answer\n",
    "```\n",
    "\n",
    "Each stage is a **LangGraph node**, forming a **cycle** until the output is “good enough”.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Self-Reflection (in LLM terms)?\n",
    "\n",
    "**Definition:**\n",
    "Self-Reflection = When an AI model evaluates its *own output* (or reasoning steps) and *adjusts them* before producing a final response.\n",
    "\n",
    "**Prompt Example:**\n",
    "\n",
    "> “Here is your previous reasoning and answer. Please critique your logic, identify any gaps or errors, and rewrite an improved version.”\n",
    "\n",
    "This turns the model from a *static responder* into a *self-evaluating reasoning system.*\n",
    "\n",
    "---\n",
    "\n",
    "## What are ReAct Agents?\n",
    "\n",
    "ReAct = **Reasoning + Acting**\n",
    "Introduced in the paper *“ReAct: Synergizing Reasoning and Acting in Language Models”* (Yao et al., 2022).\n",
    "\n",
    "A ReAct agent:\n",
    "\n",
    "* Thinks about the problem\n",
    "* Chooses an action (like a search, retrieval, or calculation)\n",
    "* Observes the result\n",
    "* Continues reasoning with updated info\n",
    "\n",
    "**Loop:**\n",
    "\n",
    "```\n",
    "Thought → Action → Observation → Thought → Final Answer\n",
    "```\n",
    "\n",
    "In LangChain and LangGraph, ReAct agents are the base for **tool-using, multi-step reasoning agents**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Combine RAG + ReAct + Reflection?\n",
    "\n",
    "| Layer         | Role                                | Outcome                 |\n",
    "| ------------- | ----------------------------------- | ----------------------- |\n",
    "| 🧠 ReAct      | Gives reasoning and decision-making | Structured thinking     |\n",
    "| 📚 RAG        | Gives factual grounding             | Real-world data         |\n",
    "| 💭 Reflection | Gives self-evaluation               | Quality and correctness |\n",
    "\n",
    "So your AI doesn’t just “talk smart” — it **thinks, checks, and improves**.\n",
    "\n",
    "---\n",
    "\n",
    "## Implementing in LangChain (Step-by-Step)\n",
    "\n",
    "Let’s build this pipeline incrementally.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Imports\n",
    "\n",
    "```python\n",
    "from langchain.llms import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Setup RAG (Retriever)\n",
    "\n",
    "```python\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma(persist_directory=\"./rag_db\", embedding_function=embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Create a Self-Reflection Prompt\n",
    "\n",
    "```python\n",
    "reflection_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"previous_answer\"],\n",
    "    template=\"\"\"\n",
    "You are a reflective AI assistant. Evaluate your previous answer critically.\n",
    "\n",
    "Question: {query}\n",
    "Previous Answer: {previous_answer}\n",
    "\n",
    "Identify:\n",
    "1. Any factual inaccuracies.\n",
    "2. Missing reasoning steps.\n",
    "3. Improvements for clarity and correctness.\n",
    "\n",
    "Then produce an improved final answer.\n",
    "\"\"\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Define LLMs\n",
    "\n",
    "```python\n",
    "llm_reason = ChatOpenAI(model=\"gpt-4o\")     # main reasoning LLM\n",
    "llm_reflect = ChatOpenAI(model=\"gpt-4o-mini\")  # lighter model for reflection\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Create RAG + Reasoning Chain\n",
    "\n",
    "```python\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_reason,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Add Reflection Loop\n",
    "\n",
    "```python\n",
    "def self_reflective_rag(query):\n",
    "    # Step 1: Generate initial answer\n",
    "    initial_answer = qa_chain.run(query)\n",
    "\n",
    "    # Step 2: Reflect and improve\n",
    "    reflection_chain = LLMChain(llm=llm_reflect, prompt=reflection_prompt)\n",
    "    improved_answer = reflection_chain.run(query=query, previous_answer=initial_answer)\n",
    "\n",
    "    return improved_answer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "```python\n",
    "response = self_reflective_rag(\"Explain LangGraph and its advantages over LangChain.\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "The model first retrieves context, then reasons, then critiques itself, and finally outputs a refined, factual response.\n",
    "\n",
    "---\n",
    "\n",
    "## Self-Reflective RAG in LangGraph\n",
    "\n",
    "Now, let’s visualize the **graph-based version** with explicit reasoning + reflection nodes.\n",
    "\n",
    "---\n",
    "\n",
    "### Node Structure\n",
    "\n",
    "| Node          | Function                             |\n",
    "| ------------- | ------------------------------------ |\n",
    "| 🔍 `retrieve` | Fetch documents from vector store    |\n",
    "| 💬 `reason`   | Use LLM to generate answer           |\n",
    "| 🔁 `reflect`  | Critique and improve previous answer |\n",
    "| 🏁 `final`    | Return improved answer               |\n",
    "\n",
    "---\n",
    "\n",
    "### Code Example\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class AgentState(dict): pass\n",
    "\n",
    "llm_reason = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_reflect = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "def retrieve_node(state):\n",
    "    q = state[\"question\"]\n",
    "    docs = retriever.get_relevant_documents(q)\n",
    "    return {\"context\": docs}\n",
    "\n",
    "def reason_node(state):\n",
    "    q, ctx = state[\"question\"], state[\"context\"]\n",
    "    answer = llm_reason.invoke(f\"Question: {q}\\nContext: {ctx}\\nAnswer thoughtfully.\")\n",
    "    return {\"answer\": answer}\n",
    "\n",
    "def reflect_node(state):\n",
    "    q, ans = state[\"question\"], state[\"answer\"]\n",
    "    reflection = llm_reflect.invoke(\n",
    "        f\"Question: {q}\\nPrevious Answer: {ans}\\nCritically evaluate and rewrite improved version.\"\n",
    "    )\n",
    "    return {\"final_answer\": reflection}\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "workflow.add_node(\"reason\", reason_node)\n",
    "workflow.add_node(\"reflect\", reflect_node)\n",
    "\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"reason\")\n",
    "workflow.add_edge(\"reason\", \"reflect\")\n",
    "workflow.add_edge(\"reflect\", END)\n",
    "\n",
    "self_reflective_rag_graph = workflow.compile()\n",
    "\n",
    "result = self_reflective_rag_graph.invoke({\"question\": \"What is a ReAct agent in LangChain?\"})\n",
    "print(result[\"final_answer\"])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Output:\n",
    "\n",
    "```\n",
    "ReAct agents combine reasoning and acting. \n",
    "They think step-by-step, decide which tools to use, observe outcomes, and revise their answers.\n",
    "(Reflection: Added missing detail about LangChain integration.)\n",
    "Final Answer: ReAct agents in LangChain are reasoning agents that use external tools and environment feedback to solve tasks iteratively.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Integrating ReAct Tools\n",
    "\n",
    "You can add **tools** like retrievers, web search, or calculators into the reasoning loop:\n",
    "\n",
    "```python\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"RAG Retriever\",\n",
    "        func=lambda q: retriever.get_relevant_documents(q),\n",
    "        description=\"Retrieve factual context from vector DB\"\n",
    "    )\n",
    "]\n",
    "\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    llm=llm_reason,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = react_agent.run(\"Find and explain what Self-Reflection in AI means.\")\n",
    "```\n",
    "\n",
    "You can now **combine this agent with reflection logic** inside the LangGraph loop — creating a *self-correcting ReAct agent.*\n",
    "\n",
    "---\n",
    "\n",
    "## Advanced: ReAct + Reflection Loop (LangGraph Hybrid)\n",
    "\n",
    "This version loops multiple times until the reflection node says output is “good”.\n",
    "\n",
    "```python\n",
    "while True:\n",
    "    answer = reason_node(state)\n",
    "    feedback = reflect_node(state)\n",
    "    if \"good\" in feedback[\"final_answer\"].lower():\n",
    "        break\n",
    "    state[\"answer\"] = feedback[\"final_answer\"]\n",
    "```\n",
    "\n",
    "This creates an **iterative feedback loop**, similar to how humans revise drafts.\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "| Aspect          | Tip                                                       |\n",
    "| --------------- | --------------------------------------------------------- |\n",
    "| 🧠 Reflection   | Use a smaller, focused model to save cost                 |\n",
    "| 🔁 Loop Control | Limit reflection iterations (2–3 loops max)               |\n",
    "| 📚 Context      | Always pass retrieved context to reflection prompt        |\n",
    "| 🧩 Memory       | Use LangGraph’s state to preserve reasoning between steps |\n",
    "| 🔍 Debug        | Print intermediate reasoning for transparency             |\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "| Use Case                | Description                                  |\n",
    "| ----------------------- | -------------------------------------------- |\n",
    "| 💬 Chatbots             | Self-correct hallucinations automatically    |\n",
    "| 🧑‍🏫 Tutors            | Evaluate and refine explanations             |\n",
    "| 📚 Knowledge Assistants | Verify factual accuracy from internal docs   |\n",
    "| ⚙️ Agents               | Auto-correct tool misuse or reasoning errors |\n",
    "\n",
    "---\n",
    "\n",
    "## Visualization of the Full Loop\n",
    "\n",
    "```\n",
    "User Query\n",
    "   ↓\n",
    "[Retriever] → Context\n",
    "   ↓\n",
    "[Reasoning Node] → Draft Answer\n",
    "   ↓\n",
    "[Reflection Node] → Critique + Improve\n",
    "   ↺ (Loop if needed)\n",
    "   ↓\n",
    "[Final Output]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Concept         | Role                            | Framework Support                           |\n",
    "| --------------- | ------------------------------- | ------------------------------------------- |\n",
    "| RAG             | Factual grounding               | LangChain (Retrievers, VectorStores)        |\n",
    "| ReAct           | Reason + Act agentic behavior   | LangChain Agents                            |\n",
    "| Self-Reflection | Self-evaluation and improvement | LangGraph loops / reflection nodes          |\n",
    "| LangGraph       | State-driven workflow           | Perfect for chaining RAG → Reason → Reflect |\n",
    "| LangChain       | Core building blocks            | LLMs, tools, retrievers                     |\n",
    "\n",
    "---\n",
    "\n",
    "## TL;DR Summary\n",
    "\n",
    "> **Self-Reflective ReAct RAG Agent =**\n",
    ">\n",
    "> 🧩 Retrieval (for facts) +\n",
    "> 🧠 ReAct (for reasoning + action) +\n",
    "> 💭 Reflection (for self-correction)\n",
    ">\n",
    "> implemented using **LangChain (logic)** + **LangGraph (workflow)**.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Use Case Summary\n",
    "\n",
    "Imagine an **AI Research Assistant**:\n",
    "\n",
    "1. Retrieves papers (RAG).\n",
    "2. Analyzes content step-by-step (ReAct).\n",
    "3. Checks its reasoning and correctness (Self-Reflection).\n",
    "4. Produces a verified summary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a379a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
