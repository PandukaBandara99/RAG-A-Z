{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7c41e9",
   "metadata": {},
   "source": [
    "# Semantic Chunking\n",
    "- SemanticChunker is a document splitter that uses embedding similarity between sentences to decide chunk boundaries.\n",
    "- It ensures that each chunk is semantically coherent and not cut off mid-thought like traditional character/token splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785b4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39054f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Semantic Chunks:\n",
      "\n",
      "Chunk 1:\n",
      "LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      "Chunk 2:\n",
      "You can create chains, agents, memory, and retrievers.\n",
      "\n",
      "Chunk 3:\n",
      "The Eiffel Tower is located in Paris.\n",
      "\n",
      "Chunk 4:\n",
      "France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "## Initialize the model\n",
    "model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "## Sample text\n",
    "text=\"\"\"\n",
    "LangChain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agents, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "## Step 1 : Split into sentences\n",
    "sentences=[s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "\n",
    "### sstep 2: Embed each setence\n",
    "embeddings=model.encode(sentences)\n",
    "\n",
    "# Step 3: Initialize parameters\n",
    "threshold = 0.7  # control chunk tightness\n",
    "chunks = []\n",
    "current_chunk=[sentences[0]]\n",
    "\n",
    "## Step 4: Semantic grouping based on threshold\n",
    "\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity(\n",
    "        [embeddings[i - 1]],\n",
    "        [embeddings[i]]\n",
    "    )[0][0]\n",
    "\n",
    "    if sim>=threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk=[sentences[i]]\n",
    "\n",
    "# Append the last chunk\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "# Output the chunks\n",
    "print(\"\\nüìå Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {idx+1}:\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908eeb1",
   "metadata": {},
   "source": [
    "### RAG Pipeline Modular Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableMap\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c799b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Semantic Chunker With Threshold\n",
    "\n",
    "class ThresholdSematicChunker:\n",
    "    def __init__(self,model_name=\"all-MiniLM-L6-v2\",threshold=0.7):\n",
    "        self.model=SentenceTransformer(model_name)\n",
    "        self.threshold=threshold \n",
    "\n",
    "    def split(self, text: str):\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        embeddings = self.model.encode(sentences)\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i - 1]], [embeddings[i]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\". \".join(current_chunk) + \".\")\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\". \".join(current_chunk) + \".\")\n",
    "        return chunks\n",
    "    \n",
    "    def split_documents(self,docs):\n",
    "        result=[]\n",
    "        for doc in docs:\n",
    "            for chunk in self.split(doc.page_content):\n",
    "                result.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7efa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='\\nLangChain is a framework for building applications with LLMs.\\nLangchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains, agents, memory, and retrievers.\\nThe Eiffel Tower is located in Paris.\\nFrance is a popular tourist destination.\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "LangChain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agents, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "doc = Document(page_content=sample_text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af673440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.'),\n",
       " Document(metadata={}, page_content='You can create chains, agents, memory, and retrievers.'),\n",
       " Document(metadata={}, page_content='The Eiffel Tower is located in Paris.'),\n",
       " Document(metadata={}, page_content='France is a popular tourist destination.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chunking\n",
    "chunker=ThresholdSematicChunker(threshold=0.7)\n",
    "chunks=chunker.split_documents([doc])\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4220a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VectorStore\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding=OpenAIEmbeddings()\n",
    "vectorstore=FAISS.from_documents(chunks,embedding)\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c65f88b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based on the following context:\\n\\n{context}\\n\\nQuestion: {question}\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "\n",
    "# --- 5. Prompt Template ---\n",
    "template = \"\"\"Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941a408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, LangChain is a framework for building applications with LLMs. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## LLM\n",
    "llm=init_chat_model(model=\"groq:gemma2-9b-it\",temperature=0.4)\n",
    "\n",
    "### LCEL Chain With retrieval\n",
    "\n",
    "rag_chain=(\n",
    "    RunnableMap(\n",
    "        {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\": lambda x: x[\"question\"],  \n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- 8. Run Query ---\n",
    "query = {\"question\": \"What is LangChain used for?\"}\n",
    "result = rag_chain.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f17648",
   "metadata": {},
   "source": [
    "### Semantic chunker With Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074a8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50907e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chunk 1:\n",
      "LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      " chunk 2:\n",
      "You can create chains, agents, memory, and retrievers. The Eiffel Tower is located in Paris. France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "## Load the documents\n",
    "loader=TextLoader(\"langchain_intro.txt\")\n",
    "docs=loader.load()\n",
    "\n",
    "## Initialize embedding model\n",
    "embedding=OpenAIEmbeddings()\n",
    "\n",
    "## Create the semantic chunker\n",
    "chunker=SemanticChunker(embedding)\n",
    "\n",
    "## Split the documents\n",
    "chunks=chunker.split_documents(docs)\n",
    "\n",
    "## Result\n",
    "\n",
    "for i,chunk in enumerate(chunks):\n",
    "    print(f\"\\n chunk {i+1}:\\n{chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e3550",
   "metadata": {},
   "source": [
    "# Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3f086",
   "metadata": {},
   "source": [
    "| **Aspect**                      | **Traditional (Fixed-Size) Chunking**                                               | **Semantic Chunking (Meaning-Based)**                                                     | **Examples / Framework Implementations**                                              |\n",
    "| ------------------------------- | ----------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------- |\n",
    "| **Definition**                  | Splits text into chunks of fixed character or token length (e.g., 500‚Äì1000 tokens). | Splits text dynamically based on meaning, context, and sentence structure.                | LangChain SemanticChunker, LlamaIndex SentenceSplitter, Haystack SemanticTextSplitter |\n",
    "| **Chunk Boundaries**            | Determined by token count, not context.                                             | Determined by semantic similarity, coherence, or embedding similarity.                    | Uses cosine similarity between embeddings to decide split points.                     |\n",
    "| **Context Preservation**        | Often breaks sentences or thoughts in half, losing meaning.                         | Preserves complete semantic units ‚Äî paragraphs, topics, or entities stay intact.          | LangChain‚Äôs `SemanticChunker` ensures minimal semantic loss.                          |\n",
    "| **Embedding Quality**           | Lower-quality embeddings due to broken context.                                     | Higher-quality embeddings since each chunk contains coherent meaning.                     | Especially effective with dense embedding models (e.g., `text-embedding-3-large`).    |\n",
    "| **Retrieval Accuracy**          | May retrieve irrelevant or partial chunks.                                          | More relevant document retrieval, as chunks align better with queries.                    | Improves recall and precision in vector search.                                       |\n",
    "| **Chunk Overlap**               | Requires manual overlap (e.g., 100‚Äì200 tokens) to maintain context continuity.      | Overlap handled naturally by meaning ‚Äî chunks overlap when context overlaps semantically. | Automatically managed via similarity threshold.                                       |\n",
    "| **Processing Cost**             | Simpler and faster ‚Äî low compute overhead.                                          | Slightly higher compute cost due to embedding-based boundary detection.                   | Overhead scales with chunk count √ó embedding dimension.                               |\n",
    "| **Best Use Cases**              | Structured text, code, or fixed-length documents.                                   | Unstructured, narrative, or multi-topic documents (PDFs, research papers, transcripts).   | Particularly useful in knowledge bases and multi-topic RAG systems.                   |\n",
    "| **Drawbacks**                   | Loses semantic meaning and cross-sentence context.                                  | Slower and more complex preprocessing pipeline.                                           | Trade-off: quality vs. speed.                                                         |\n",
    "| **Integration with Vector DBs** | Works fine with any vector store (Chroma, Pinecone, FAISS).                         | Works best with high-dimensional vector DBs and metadata filtering.                       | Chroma + LangChain SemanticChunker combination works very well.                       |\n",
    "| **Example Pipeline**            | `RecursiveCharacterTextSplitter` ‚Üí Embed ‚Üí Store ‚Üí Retrieve                         | `SemanticChunker` ‚Üí Compute embeddings ‚Üí Segment semantically ‚Üí Store ‚Üí Retrieve          | LangChain `SemanticChunker` + `OpenAIEmbeddings` + Chroma                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc043e",
   "metadata": {},
   "source": [
    "| **Metric**                | **Traditional Chunking** | **Semantic Chunking**            |\n",
    "| ------------------------- | ------------------------ | -------------------------------- |\n",
    "| Context Retention         | ‚ùå Often lost             | ‚úÖ Preserved                      |\n",
    "| Embedding Relevance       | ‚ö™ Medium                 | üü¢ High                          |\n",
    "| Retrieval Precision       | ‚ö™ Average                | üü¢ Strong                        |\n",
    "| Computation Cost          | üü¢ Low                   | üî¥ Moderate                      |\n",
    "| Implementation Complexity | üü¢ Simple                | üî¥ Moderate                      |\n",
    "| Ideal For                 | Structured / short text  | Unstructured / long-form content |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686355d0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
