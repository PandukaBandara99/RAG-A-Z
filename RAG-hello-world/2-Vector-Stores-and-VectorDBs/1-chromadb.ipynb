{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e222d7e9",
   "metadata": {},
   "source": [
    "# Building a RAG System with LangChain and ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05eac1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb9cb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ec2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## langchain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "## vectorstores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "## utility imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f024579e",
   "metadata": {},
   "source": [
    "### RAG (Retrieval-Augmented Generation) Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50566433",
   "metadata": {},
   "source": [
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef678d",
   "metadata": {},
   "source": [
    "## Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2248bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Save Sample Documents to Temporary Text Files\n",
    "# ------------------------------------------------------------\n",
    "# This script demonstrates how to:\n",
    "# 1. Create a temporary directory using Python's `tempfile` module.\n",
    "# 2. Write multiple text documents into that directory.\n",
    "# 3. Print the directory path where files are stored.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import tempfile  # Provides utilities for creating temporary files and directories\n",
    "\n",
    "# Step 1: Create a temporary directory\n",
    "# ------------------------------------\n",
    "# `tempfile.mkdtemp()` creates a unique temporary directory\n",
    "# which is automatically cleaned up when the system reboots or manually deleted.\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Step 2: Write each document to a separate text file\n",
    "# ---------------------------------------------------\n",
    "# `enumerate(sample_docs)` gives both index (i) and content (doc)\n",
    "# Each document is saved as: doc_0.txt, doc_1.txt, doc_2.txt, etc.\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    # Open a new text file in write mode ('w')\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\", \"w\") as f:\n",
    "        # Write the content of the document into the file\n",
    "        f.write(doc)\n",
    "\n",
    "# Step 3: Print the directory path\n",
    "# --------------------------------\n",
    "# Display the temporary directory location to help locate saved documents.\n",
    "print(f\"Sample documents created in: {temp_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6907ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\win10\\\\AppData\\\\Local\\\\Temp\\\\tmp36cdbi28'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada15124",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b48ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview:\n",
      "\n",
      "    Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. Ther...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load Documents from a Directory\n",
    "# ------------------------------------------------------------\n",
    "# This script demonstrates how to:\n",
    "# 1. Use LangChain's DirectoryLoader to load multiple text files.\n",
    "# 2. Specify custom file-matching patterns and loader configurations.\n",
    "# 3. Preview the content of loaded documents.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# Step 1: Initialize the Directory Loader\n",
    "# ---------------------------------------\n",
    "# DirectoryLoader helps automatically load all files from a directory.\n",
    "# Parameters:\n",
    "# - \"data\" : Path to the folder containing text files.\n",
    "# - glob=\"*.txt\" : File matching pattern â€” only loads `.txt` files.\n",
    "# - loader_cls=TextLoader : Specifies that each file is loaded as text.\n",
    "# - loader_kwargs : Extra arguments passed to the TextLoader (e.g., encoding type).\n",
    "loader = DirectoryLoader(\n",
    "    \"data\", \n",
    "    glob=\"*.txt\", \n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}  # Ensures text files are correctly decoded\n",
    ")\n",
    "\n",
    "# Step 2: Load all matching documents\n",
    "# -----------------------------------\n",
    "# The `load()` method reads all the matched files and converts them\n",
    "# into LangChain `Document` objects â€” each with metadata and content.\n",
    "documents = loader.load()\n",
    "\n",
    "# Step 3: Display summary information\n",
    "# -----------------------------------\n",
    "# Print how many documents were successfully loaded.\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "# Step 4: Preview the first document\n",
    "# -----------------------------------\n",
    "# Safely display a small snippet of the first documentâ€™s content.\n",
    "print(\"\\nFirst document preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")  # Show first 200 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851ae9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688807d4",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3620217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 chunks from 3 documents\n",
      "\n",
      "Chunk example:\n",
      "Content: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experie...\n",
      "Metadata: {'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Text Splitting into Manageable Chunks\n",
    "# ------------------------------------------------------------\n",
    "# This script demonstrates how to:\n",
    "# 1. Initialize LangChain's RecursiveCharacterTextSplitter.\n",
    "# 2. Divide large documents into smaller, overlapping chunks.\n",
    "# 3. Preserve contextual flow across chunks.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step 1: Initialize the Text Splitter\n",
    "# ------------------------------------\n",
    "# RecursiveCharacterTextSplitter intelligently splits text into smaller chunks\n",
    "# while trying to respect natural language boundaries (e.g., sentences, spaces).\n",
    "# Parameters:\n",
    "# - chunk_size: Maximum number of characters in each chunk.\n",
    "# - chunk_overlap: Number of overlapping characters between adjacent chunks.\n",
    "#   (Useful to retain context for models like embeddings or LLMs.)\n",
    "# - length_function: Function used to measure text length (here we use `len`).\n",
    "# - separators: Defines hierarchy for splitting (e.g., paragraph, sentence, space).\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,       # Each chunk will be around 500 characters\n",
    "    chunk_overlap=50,     # Overlap ensures continuity of meaning across chunks\n",
    "    length_function=len,  # Length is measured in number of characters\n",
    "    separators=[\" \"]      # Splitting primarily based on spaces\n",
    ")\n",
    "\n",
    "# Step 2: Split the documents\n",
    "# ----------------------------\n",
    "# The splitter divides each document into multiple smaller segments,\n",
    "# returning a list of `Document` objects â€” each containing a chunk of text\n",
    "# along with inherited metadata (e.g., source file).\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Step 3: Display results\n",
    "# ------------------------\n",
    "# Provide an overview of how many chunks were created and preview one of them.\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "\n",
    "# Step 4: Inspect an example chunk\n",
    "# --------------------------------\n",
    "# Show a short snippet from the first chunk for verification.\n",
    "print(\"\\nChunk example:\")\n",
    "print(f\"Content: {chunks[0].page_content[:150]}...\")  # First 150 characters\n",
    "print(f\"Metadata: {chunks[0].metadata}\")               # Associated metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bccc475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8485c41",
   "metadata": {},
   "source": [
    "### Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c6c93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1491c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000001D9674BECF0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000001D9674BF620>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text=\"MAchine LEarning is fascinating\"\n",
    "embeddings=OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e814386",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=embeddings.embed_query(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424dc3d",
   "metadata": {},
   "source": [
    "### Intilialize the ChromaDB Vector Store And Stores the chunks in Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fe48585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 10 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Create and Persist a Chroma Vector Store\n",
    "# ------------------------------------------------------------\n",
    "# This section creates a local vector database using Chroma\n",
    "# and stores text embeddings for efficient retrieval.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Directory path where the vector store will be saved\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Initialize Chroma with precomputed text chunks and embeddings\n",
    "# - `documents`: list of chunked text data\n",
    "# - `embedding`: embedding model (OpenAI embeddings used here)\n",
    "# - `persist_directory`: location to save the vector index\n",
    "# - `collection_name`: logical grouping name for the stored vectors\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "# Display summary information\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe5ad8",
   "metadata": {},
   "source": [
    "## Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85a306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Query the Chroma Vector Store\n",
    "# ------------------------------------------------------------\n",
    "# Perform a semantic similarity search to find documents\n",
    "# most relevant to a given natural language query.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Define a natural language query\n",
    "query = \"What are the types of machine learning?\"\n",
    "\n",
    "# Perform similarity search\n",
    "# - Converts the query into an embedding vector\n",
    "# - Retrieves the top-k most similar document chunks\n",
    "# - Returns LangChain `Document` objects with content and metadata\n",
    "similar_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "# Display results\n",
    "print(f\"âœ… Retrieved {len(similar_docs)} relevant chunks:\\n\")\n",
    "for i, doc in enumerate(similar_docs, 1):\n",
    "    print(f\"ðŸ”¹ Result {i}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Preview first 200 characters\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f103e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"what is NLP?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1ad450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"what is Deep Learning?\"\n",
    "\n",
    "similar_docs=vectorstore.similarity_search(query,k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af936dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what is Deep Learning?\n",
      "\n",
      "Top 3 similar chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "Source: data\\doc_1.txt\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "Source: data\\doc_1.txt\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "Source: data\\doc_0.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nTop {len(similar_docs)} similar chunks:\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96130b",
   "metadata": {},
   "source": [
    "## Advanced Similarity Search With Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05714c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  0.23813432455062866),\n",
       " (Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  0.2383197844028473),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.35702383518218994)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Perform similarity search with scores\n",
    "# ------------------------------------------------------------\n",
    "# Returns the top-k most similar documents along with\n",
    "# their similarity scores (lower = more similar).\n",
    "# Each result is a tuple: (Document, score)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "results_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "results_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa87ef",
   "metadata": {},
   "source": [
    "## Understanding Similarity Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d764ffd",
   "metadata": {},
   "source": [
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98d2c5",
   "metadata": {},
   "source": [
    "## Initialize LLM, RAG Chain, Prompt Template,Query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e11208d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "318caf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Large Language Models (LLMs) are a type of artificial intelligence model that have the ability to generate and understand human language at a large scale. These models are trained on massive amounts of text data, allowing them to produce coherent and human-like text in responses to prompts or queries. Some well-known examples of LLMs include OpenAI's GPT-3 and Google's BERT. These models have a wide range of applications, including natural language processing, text generation, and dialogue generation.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 12, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bx8e1mrx70gI0XqLI3sdVxQDO8J2Z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a16ee603-82ed-4480-8aa3-f89d5a56c49a-0', usage_metadata={'input_tokens': 12, 'output_tokens': 99, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response=llm.invoke(\"What is Large Language Models\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "155ed230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D96AA93110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D96AA92FD0>, root_client=<openai.OpenAI object at 0x000001D96AB19810>, root_async_client=<openai.AsyncOpenAI object at 0x000001D96AB196E0>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models.base import init_chat_model\n",
    "\n",
    "llm=init_chat_model(\"openai:gpt-3.5-turbo\")\n",
    "#llm=init_chat_model(\"groq:\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d478885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI, or artificial intelligence, is the simulation of human intelligence processes by machines. These processes include learning, reasoning, problem-solving, perception, and language understanding. AI technologies are used in a wide range of applications, such as speech recognition, natural language processing, image recognition, and robotics.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 10, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bx8e8mjKa0JsflCAr1zExfdW3ASlJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2715a612-f118-4c13-8de1-6b72506ae34c-0', usage_metadata={'input_tokens': 10, 'output_tokens': 58, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef478ac6",
   "metadata": {},
   "source": [
    "### Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d2fce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72069a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D9674BFB60>, search_kwargs={})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Create a Retriever from the Vector Store\n",
    "# ------------------------------------------------------------\n",
    "# A retriever provides an easy interface to fetch the most\n",
    "# relevant document chunks for a given query.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}  # Retrieve top 3 most relevant chunks\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20c9ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5beb8805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c970780",
   "metadata": {},
   "source": [
    "## What is create_stuff_documents_chain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b12cd",
   "metadata": {},
   "source": [
    "create_stuff_documents_chain creates a chain that \"stuffs\" (inserts) all retrieved documents into a single prompt and sends it to the LLM. It's called \"stuff\" because it literally stuffs all the documents into the context window at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a79afdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D96AA93110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D96AA92FD0>, root_client=<openai.OpenAI object at 0x000001D96AB19810>, root_async_client=<openai.AsyncOpenAI object at 0x000001D96AB196E0>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create a document chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2630f2",
   "metadata": {},
   "source": [
    "This chain:\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d67cf5",
   "metadata": {},
   "source": [
    "## What is create_retrieval_chain?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4abe896",
   "metadata": {},
   "source": [
    "create_retrieval_chain is a function that combines a retriever (which fetches relevant documents) with a document chain (which processes those documents with an LLM) to create a complete RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21706431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D9674BFB60>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D96AA93110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D96AA92FD0>, root_client=<openai.OpenAI object at 0x000001D96AB19810>, root_async_client=<openai.AsyncOpenAI object at 0x000001D96AB196E0>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create The Final RAG Chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "rag_chain=create_retrieval_chain(retriever,document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7a92b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=rag_chain.invoke({\"input\":\"What is Deep LEarning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36712cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Deep LEarning',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')],\n",
       " 'answer': 'Deep learning is a subset of machine learning that relies on artificial neural networks inspired by the human brain, consisting of interconnected layers of nodes. It has significantly advanced fields such as computer vision, natural language processing, and speech recognition. Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformers are commonly used architectures in deep learning for tasks like image processing and sequential data analysis.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "643b720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning that relies on artificial neural networks inspired by the human brain, consisting of interconnected layers of nodes. It has significantly advanced fields such as computer vision, natural language processing, and speech recognition. Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformers are commonly used architectures in deep learning for tasks like image processing and sequential data analysis.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9528d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the three types of machine learning?\n",
      "--------------------------------------------------\n",
      "Answer: The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through feedback from the environment.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "\n",
      "--- Source 2 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "\n",
      "--- Source 3 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 4 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What is deep learning and how does it relate to neural networks?\n",
      "--------------------------------------------------\n",
      "Answer: Deep learning is a subset of machine learning that relies on artificial neural networks inspired by the human brain. These neural networks consist of interconnected nodes organized in layers. Deep learning has significantly advanced fields such as computer vision, natural language processing, and speech recognition.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 3 ---\n",
      "Neural Networks (RNNs) and Transformers \n",
      "    excel at sequential data processing....\n",
      "\n",
      "--- Source 4 ---\n",
      "Neural Networks (RNNs) and Transformers \n",
      "    excel at sequential data processing....\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What are CNNs best used for?\n",
      "--------------------------------------------------\n",
      "Answer: CNNs are particularly effective for image processing due to their ability to capture spatial hierarchies in data.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 3 ---\n",
      "Neural Networks (RNNs) and Transformers \n",
      "    excel at sequential data processing....\n",
      "\n",
      "--- Source 4 ---\n",
      "Neural Networks (RNNs) and Transformers \n",
      "    excel at sequential data processing....\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Function: Query the Modern RAG System\n",
    "# ------------------------------------------------------------\n",
    "# This function sends a user question through the Retrieval-Augmented\n",
    "# Generation (RAG) pipeline using `rag_chain.invoke()`.\n",
    "# It prints both the final answer and the retrieved source context.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def query_rag_modern(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Run the query through the RAG chain\n",
    "    # - \"input\" is passed to the chain, which handles retrieval + LLM response\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "    \n",
    "    # Display the generated answer\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    \n",
    "    # Show retrieved document context for transparency\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")  # Preview first 200 chars\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Test Queries for the RAG System\n",
    "# ------------------------------------------------------------\n",
    "# Each query tests retrieval accuracy and reasoning quality\n",
    "# of the integrated RAG pipeline.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "test_questions = [\n",
    "    \"What are the three types of machine learning?\",\n",
    "    \"What is deep learning and how does it relate to neural networks?\",\n",
    "    \"What are CNNs best used for?\"\n",
    "]\n",
    "\n",
    "# Run the test queries and display results\n",
    "for question in test_questions:\n",
    "    result = query_rag_modern(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")  # Separator between results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95621f",
   "metadata": {},
   "source": [
    "## Create RAG Chain Alternative - Using LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2648ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even more flexible approach using LCEL\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b38f31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"Use the following context to answer the question. \n",
    "If you don't know the answer based on the context, say you don't know.\n",
    "Provide specific details from the context to support your answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\")\n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64c39bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D9674BFB60>, search_kwargs={})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb38511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format the output documents for the prompt\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ece729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D9674BFB60>, search_kwargs={})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D96AA93110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D96AA92FD0>, root_client=<openai.OpenAI object at 0x000001D96AB19810>, root_async_client=<openai.AsyncOpenAI object at 0x000001D96AB196E0>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Build a Modern RAG Chain using LangChain Execution Layer (LCEL)\n",
    "# ------------------------------------------------------------\n",
    "# This pipeline integrates retrieval, prompt formatting, LLM generation,\n",
    "# and output parsing into a single executable chain.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "rag_chain_lcel = (\n",
    "    {\n",
    "        # Retrieve relevant documents and format them for the prompt\n",
    "        \"context\": retriever | format_docs,\n",
    "        # Pass the user's question directly without modification\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    # Apply a custom prompt template using the retrieved context and question\n",
    "    | custom_prompt\n",
    "    # Generate the answer using the chosen LLM\n",
    "    | llm\n",
    "    # Parse the LLM output into a clean string\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Display the LCEL RAG chain object\n",
    "rag_chain_lcel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662d849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning based on artificial neural networks. These networks consist of layers of interconnected nodes, inspired by the human brain, and have revolutionized fields like computer vision, natural language processing, and speech recognition.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Query the LCEL RAG Chain\n",
    "# ------------------------------------------------------------\n",
    "# Sends a natural language question through the fully integrated\n",
    "# retrieval + LLM pipeline and returns the generated answer.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Invoke the chain with a user question\n",
    "response = rag_chain_lcel.invoke(\"What is Deep Learning\")\n",
    "\n",
    "# Display the raw response\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ef293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Retrieve Relevant Documents Using the Retriever\n",
    "# ------------------------------------------------------------\n",
    "# Fetches the most relevant documents for a given query without\n",
    "# running them through the LLM. Useful for inspecting context.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "retriever.get_relevant_documents(\"What is Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eb95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Query the RAG System using the LCEL Approach\n",
    "# ------------------------------------------------------------\n",
    "# This function sends a user question through the LCEL-based RAG chain\n",
    "# and optionally retrieves the supporting source documents.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def query_rag_lcel(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Step 1: Generate answer using LCEL RAG chain\n",
    "    # - Directly pass the question string (RunnablePassthrough handles it)\n",
    "    answer = rag_chain_lcel.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "    \n",
    "    # Step 2: Retrieve supporting documents (optional)\n",
    "    # - Fetches the top-k most relevant chunks from the retriever\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    print(\"\\nSource Documents:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")  # Show first 200 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fac30700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LCEL Chain:\n",
      "Question: What are the key concepts in reinforcement learning?\n",
      "--------------------------------------------------\n",
      "Answer: The key concepts in reinforcement learning are interaction with an environment, using rewards and penalties for learning. This involves the system learning through trial and error, receiving feedback in the form of rewards and penalties to adjust its behavior.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "--- Source 1 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      "--- Source 2 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      "--- Source 3 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "\n",
      "--- Source 4 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n"
     ]
    }
   ],
   "source": [
    "# Test LCEL chain\n",
    "print(\"Testing LCEL Chain:\")\n",
    "query_rag_lcel(\"What are the key concepts in reinforcement learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0e5f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is machine learning?\n",
      "--------------------------------------------------\n",
      "Answer: Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It consists of three main types: supervised learning, unsupervised learning, and reinforcement learning.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "--- Source 1 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "\n",
      "--- Source 2 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "\n",
      "--- Source 3 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 4 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n"
     ]
    }
   ],
   "source": [
    "query_rag_lcel(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7530816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is depe learning?\n",
      "--------------------------------------------------\n",
      "Answer: Deep learning is a subset of machine learning based on artificial neural networks. These networks consist of layers of interconnected nodes and are inspired by the human brain. Deep learning has revolutionized fields such as computer vision, natural language processing, and speech recognition. Convolutional Neural Networks (CNNs) are especially effective for image processing in deep learning.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n",
      "\n",
      "--- Source 3 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n",
      "\n",
      "--- Source 4 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n"
     ]
    }
   ],
   "source": [
    "query_rag_lcel(\"What is depe learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869510c",
   "metadata": {},
   "source": [
    "## Add New Documents To Existing Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c464cf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1d9674bfb60>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c379255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new documents to the existing vector store\n",
    "new_document = \"\"\"\n",
    "Reinforcement Learning in Detail\n",
    "\n",
    "Reinforcement learning (RL) is a type of machine learning where an agent learns to make \n",
    "decisions by interacting with an environment. The agent receives rewards or penalties \n",
    "based on its actions and learns to maximize cumulative reward over time. Key concepts \n",
    "in RL include: states, actions, rewards, policies, and value functions. Popular RL \n",
    "algorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \n",
    "Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \n",
    "robotics, and autonomous systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b431aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7bd5df9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "894dd275",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc=Document(\n",
    "    page_content=new_document,\n",
    "    metadata={\"source\": \"manual_addition\", \"topic\": \"reinforcement_learning\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15f35837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.\\n')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16202c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='Reinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## split the documents\n",
    "new_chunks=text_splitter.split_documents([new_doc])\n",
    "new_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f91ae2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b9b7448a-f68b-4593-a297-84e5697793f6',\n",
       " '4669dce8-2bbb-4d08-a11c-1f8b9ab2c01b']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add new documents to vectorstore\n",
    "vectorstore.add_documents(new_chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3384f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 new chunks to the vector store\n",
      "Total vectors now: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Added {len(new_chunks)} new chunks to the vector store\")\n",
    "print(f\"Total vectors now: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32c2680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the keys concepts in reinforcement learning\n",
      "--------------------------------------------------\n",
      "Answer: The key concepts in reinforcement learning include states, actions, rewards, policies, and value functions.\n",
      "\n",
      "Source Documents:\n",
      "\n",
      "--- Source 1 ---\n",
      "Reinforcement Learning in Detail\n",
      "\n",
      "Reinforcement learning (RL) is a type of machine learning where an agent learns to make \n",
      "decisions by interacting with an environment. The agent receives rewards or p...\n",
      "\n",
      "--- Source 2 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      "--- Source 3 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      "--- Source 4 ---\n",
      "methods, and \n",
      "Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \n",
      "robotics, and autonomous systems....\n"
     ]
    }
   ],
   "source": [
    "## query with the updated vector\n",
    "new_question=\"What are the keys concepts in reinforcement learning\"\n",
    "result=query_rag_lcel(new_question)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd68b1f",
   "metadata": {},
   "source": [
    "## Advanced Rag Techniques- Conversational Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36e698",
   "metadata": {},
   "source": [
    "Understanding Conversational Memory in RAG\n",
    "Conversational memory enables RAG systems to maintain context across multiple interactions. This is crucial for:\n",
    "\n",
    "Follow-up questions that reference previous answers\n",
    "Pronoun resolution (e.g., \"it\", \"they\", \"that\")\n",
    "Context-dependent queries that build on prior discussion\n",
    "Natural dialogue flow where users don't repeat context\n",
    "\n",
    "Key Challenge:\n",
    "Traditional RAG retrieves documents based only on the current query, missing important context from the conversation. For example:\n",
    "\n",
    "User: \"Tell me about Python\"\n",
    "Bot: explains Python programming language\n",
    "User: \"What are its main libraries?\" â† \"its\" refers to Python, but retriever doesn't know this\n",
    "\n",
    "Solution:\n",
    "The modern approach uses a two-step process:\n",
    "\n",
    "Query Reformulation: Transform context-dependent questions into standalone queries\n",
    "Context-Aware Retrieval: Use the reformulated query to fetch relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9189de7",
   "metadata": {},
   "source": [
    "- create_history_aware_retriever: Makes the retriever understand conversation context\n",
    "- MessagesPlaceholder: Placeholder for chat history in prompts\n",
    "- HumanMessage/AIMessage: Structured message types for conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7198db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eaa69a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a prompt that includes the chat history\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \n",
    "which might reference context in the chat history, formulate a standalone question \n",
    "which can be understood without the chat history. Do NOT answer the question, \n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4424ee54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D9674BFB60>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001D9367196C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question \\nwhich might reference context in the chat history, formulate a standalone question \\nwhich can be understood without the chat history. Do NOT answer the question, \\njust reformulate it if needed and otherwise return it as is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D96AA93110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D96AA92FD0>, root_client=<openai.OpenAI object at 0x000001D96AB19810>, root_async_client=<openai.AsyncOpenAI object at 0x000001D96AB196E0>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001D9674BFB60>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create history aware retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "49143814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational RAG chain created!\n"
     ]
    }
   ],
   "source": [
    "# Create a new document chain with history\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create conversational RAG chain\n",
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriever, \n",
    "    question_answer_chain\n",
    ")\n",
    "print(\"Conversational RAG chain created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d7aa4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is machine learning?\n",
      "A: Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It encompasses supervised learning, unsupervised learning, and reinforcement learning as its main types. In supervised learning, models are trained using labeled data, while unsupervised learning identifies patterns in unlabeled data.\n"
     ]
    }
   ],
   "source": [
    "chat_history=[]\n",
    "# First question\n",
    "result1 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What is machine learning?\"\n",
    "})\n",
    "print(f\"Q: What is machine learning?\")\n",
    "print(f\"A: {result1['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "628e28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend([\n",
    "    HumanMessage(content=\"What is machine learning\"),\n",
    "    AIMessage(content=result1['answer'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "234e65ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is machine learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It encompasses supervised learning, unsupervised learning, and reinforcement learning as its main types. In supervised learning, models are trained using labeled data, while unsupervised learning identifies patterns in unlabeled data.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67bca7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='What is machine learning', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It encompasses supervised learning, unsupervised learning, and reinforcement learning as its main types. In supervised learning, models are trained using labeled data, while unsupervised learning identifies patterns in unlabeled data.', additional_kwargs={}, response_metadata={})],\n",
       " 'input': 'What are its main types?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')],\n",
       " 'answer': 'The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning learns through a system of reward and punishment.'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Follow up question\n",
    "# Follow-up question\n",
    "result2 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What are its main types?\"  # Refers to ML from previous question\n",
    "})\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d28231be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data. Reinforcement learning learns through a system of reward and punishment.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e708a",
   "metadata": {},
   "source": [
    "## Using GROQ LLM's\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0da1e8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D96AA93110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D96AA92FD0>, root_client=<openai.OpenAI object at 0x000001D96AB19810>, root_async_client=<openai.AsyncOpenAI object at 0x000001D96AB196E0>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd7312bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92bacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36d21da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6c68732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9c759127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001D9741897F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D974189BE0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatGroq(model=\"gemma2-9b-it\",api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b0e7c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001D9742AB110>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D9742AB610>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=init_chat_model(model=\"groq:gemma2-9b-it\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef59c57",
   "metadata": {},
   "source": [
    "# **Additional Notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf091ac",
   "metadata": {},
   "source": [
    "## **ChromaDB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271208c",
   "metadata": {},
   "source": [
    "### **Introduction to Chroma DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd4a54b",
   "metadata": {},
   "source": [
    "**1. What is Chroma DB?**\n",
    "\n",
    "**Chroma DB** is an open-source vector database designed to efficiently store, manage, and query high-dimensional embeddings generated by machine learning models. It is optimized for similarity search, recommendation systems, and other applications that require working with vector representations of data.\n",
    "\n",
    "Key highlights:\n",
    "\n",
    "* Fast vector similarity search using advanced indexing techniques.\n",
    "* Integrates seamlessly with machine learning pipelines.\n",
    "* Supports rich metadata for documents to enable contextual filtering.\n",
    "* Scales for both small projects and industrial-level workloads.\n",
    "\n",
    "\n",
    "**2. Overview of Chroma DB**\n",
    "\n",
    "Chroma DB acts as a bridge between raw data and intelligent applications that rely on vector representations:\n",
    "\n",
    "* It stores **vectors (embeddings)** produced by models such as OpenAI embeddings, SentenceTransformers, etc.\n",
    "* Enables **efficient querying** to find vectors similar to a given input vector (nearest neighbor search).\n",
    "* Organizes data in **collections** with metadata for easier filtering and management.\n",
    "\n",
    "\n",
    "**3. Use Cases and Applications**\n",
    "\n",
    "Chroma DB is widely used in scenarios involving **similarity search** and **semantic retrieval**:\n",
    "\n",
    "* **Semantic Search:** Retrieve documents, images, or media relevant to a query vector.\n",
    "* **Recommendation Systems:** Suggest items similar to user preferences based on embeddings.\n",
    "* **Chatbots and RAG (Retrieval-Augmented Generation):** Retrieve contextually relevant documents for generating answers.\n",
    "* **Anomaly Detection:** Identify outliers in high-dimensional feature space.\n",
    "* **Image, Audio, and Video Search:** Use embeddings to find similar multimedia content.\n",
    "\n",
    "**Core Concepts**\n",
    "\n",
    "a. Vectors and Embeddings\n",
    "\n",
    "* **Vector:** A numeric representation of an object in high-dimensional space (e.g., `[0.23, -0.14, 0.98]`).\n",
    "* **Embedding:** A transformation of data (text, image, audio) into a vector, capturing semantic meaning.\n",
    "* **Similarity Search:** Use metrics like cosine similarity or Euclidean distance to find vectors closest to a query.\n",
    "\n",
    "b. Collections, Documents, and Metadata\n",
    "\n",
    "* **Collection:** A container in Chroma DB to organize related vectors. Think of it as a table in relational databases.\n",
    "* **Document:** A single entry in a collection, usually consisting of:\n",
    "\n",
    "  * **Embedding vector**\n",
    "  * **Content** (optional raw data like text or image reference)\n",
    "  * **Metadata** (key-value pairs for filtering and organization)\n",
    "\n",
    "c. Tenancy and Database Hierarchies\n",
    "\n",
    "* **Tenancy:** Supports isolation of data for different users or applications.\n",
    "* **Database Hierarchy:**\n",
    "\n",
    "  * **Database:** Top-level container\n",
    "  * **Collection:** Logical grouping within a database\n",
    "  * **Document/Vector:** Individual entries within a collection\n",
    "\n",
    "---\n",
    "**5. Installation and Setup**\n",
    "\n",
    "a. System Requirements\n",
    "\n",
    "* **Python:** Version 3.8 or higher\n",
    "* **OS:** Cross-platform (Linux, Windows, macOS)\n",
    "* **Memory:** Dependent on dataset size, typically 8GB+ recommended for medium workloads\n",
    "\n",
    "b. Installing Chroma DB\n",
    "\n",
    "Chroma DB can be installed via Pythonâ€™s `pip`:\n",
    "\n",
    "```bash\n",
    "pip install chromadb\n",
    "```\n",
    "\n",
    "Optional dependencies for enhanced performance:\n",
    "\n",
    "```bash\n",
    "pip install chromadb[duckdb]\n",
    "```\n",
    "\n",
    "c. Setting up Your First Collection\n",
    "\n",
    "1. **Import Chroma DB client:**\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings())\n",
    "```\n",
    "\n",
    "2. **Create a collection:**\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(\"my_first_collection\")\n",
    "```\n",
    "\n",
    "3. **Add documents with embeddings:**\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=[\"Hello world\", \"Chroma DB is great!\"],\n",
    "    embeddings=[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n",
    "    metadatas=[{\"source\": \"doc1\"}, {\"source\": \"doc2\"}],\n",
    "    ids=[\"1\", \"2\"]\n",
    ")\n",
    "```\n",
    "\n",
    "4. **Query similar embeddings:**\n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_embeddings=[[0.1, 0.2, 0.3]],\n",
    "    n_results=1\n",
    ")\n",
    "print(results)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e340be56",
   "metadata": {},
   "source": [
    "### **Creating and Managing Collections in Chroma DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a620119",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b915b903",
   "metadata": {},
   "source": [
    "**1. Defining Collections**\n",
    "\n",
    "> A **collection** in Chroma DB is a container for storing related vectors (embeddings) along with their documents and metadata. Collections help organize data and enable efficient querying.\n",
    "\n",
    "**Steps to Define a Collection**\n",
    "\n",
    "1. **Initialize Chroma Client:**\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings())\n",
    "```\n",
    "\n",
    "2. **Create a Collection:**\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(\n",
    "    name=\"my_collection\",\n",
    "    metadata={\"description\": \"A collection for demo purposes\"}\n",
    ")\n",
    "```\n",
    "\n",
    "* `name`: Unique name of the collection\n",
    "* `metadata` (optional): Key-value pairs describing the collection\n",
    "\n",
    "3. **Retrieve an Existing Collection:**\n",
    "\n",
    "```python\n",
    "collection = client.get_collection(\"my_collection\")\n",
    "```\n",
    "\n",
    "4. **List All Collections:**\n",
    "\n",
    "```python\n",
    "collections = client.list_collections()\n",
    "print([c.name for c in collections])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**2. Adding and Removing Documents**\n",
    "\n",
    "a. Adding Documents\n",
    "\n",
    "A **document** in Chroma DB includes:\n",
    "\n",
    "* **embedding vector**: Numeric representation of the content\n",
    "* **content**: Optional raw data\n",
    "* **metadata**: Optional key-value pairs\n",
    "* **id**: Unique identifier\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=[\"Hello Chroma\", \"Vector databases are powerful!\"],\n",
    "    embeddings=[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n",
    "    metadatas=[{\"type\": \"greeting\"}, {\"type\": \"statement\"}],\n",
    "    ids=[\"doc1\", \"doc2\"]\n",
    ")\n",
    "```\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* Vectors should all have the **same dimension**.\n",
    "* Metadata allows for **filtered queries** later.\n",
    "\n",
    "b. Removing Documents\n",
    "\n",
    "Documents can be removed by their **IDs**:\n",
    "\n",
    "```python\n",
    "collection.delete(ids=[\"doc1\"])\n",
    "```\n",
    "\n",
    "* Deletes only the specified documents.\n",
    "* You can also remove documents based on metadata using filters:\n",
    "\n",
    "```python\n",
    "collection.delete(where={\"type\": \"statement\"})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "3. Modifying Collection Metadata\n",
    "\n",
    "Collections can have metadata attached for organizational purposes. This metadata can be **updated or modified** after creation.\n",
    "\n",
    "a. Updating Metadata:\n",
    "\n",
    "```python\n",
    "collection.update(\n",
    "    metadata={\"description\": \"Updated description for my collection\"}\n",
    ")\n",
    "```\n",
    "\n",
    "* This changes the collectionâ€™s metadata without affecting the stored documents.\n",
    "\n",
    "b. Retrieving Metadata:\n",
    "\n",
    "```python\n",
    "print(collection.metadata)\n",
    "```\n",
    "\n",
    "* Displays the key-value pairs associated with the collection.\n",
    "\n",
    "c. Use Cases for Metadata:\n",
    "\n",
    "* Descriptions, tags, or versioning of the collection\n",
    "* Categorizing collections by project, domain, or data type\n",
    "* Enabling filtered queries at the collection level\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Operation         | Method              | Example                                                        |\n",
    "| ----------------- | ------------------- | -------------------------------------------------------------- |\n",
    "| Create Collection | `create_collection` | `client.create_collection(\"my_collection\")`                    |\n",
    "| Get Collection    | `get_collection`    | `client.get_collection(\"my_collection\")`                       |\n",
    "| List Collections  | `list_collections`  | `client.list_collections()`                                    |\n",
    "| Add Document      | `add`               | `collection.add(documents=[...], embeddings=[...], ids=[...])` |\n",
    "| Delete Document   | `delete`            | `collection.delete(ids=[\"doc1\"])`                              |\n",
    "| Update Metadata   | `update`            | `collection.update(metadata={\"key\":\"value\"})`                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b8646",
   "metadata": {},
   "source": [
    "### **Storage, Persistence, Indexing, and Retrieval in Chroma DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1a647",
   "metadata": {},
   "source": [
    "**1. Storage and Persistence**\n",
    "\n",
    "> Chroma DB provides options to **persist your vector data** so it is not lost when the application stops. Understanding storage and persistence is crucial for production-grade deployments.\n",
    "\n",
    "a. Understanding the Persistent Directory\n",
    "\n",
    "* By default, Chroma DB can run **in-memory**, meaning data is lost after the process ends.\n",
    "* To persist data, Chroma DB stores vectors, documents, and metadata in a **persistent directory**:\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings(\n",
    "    persist_directory=\"./chroma_data\"  # specify your directory\n",
    "))\n",
    "```\n",
    "\n",
    "* The `persist_directory` ensures that all collections and documents are saved to disk.\n",
    "* After modifying or adding documents, call `client.persist()` to save changes:\n",
    "\n",
    "```python\n",
    "client.persist()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "b. Managing Storage Backends\n",
    "\n",
    "Chroma DB supports multiple storage backends, such as **DuckDB** and **SQLite**, for storing persistent data:\n",
    "\n",
    "* **DuckDB**: Fast analytical database; recommended for large-scale workloads\n",
    "* **SQLite**: Lightweight, easy to set up; good for small projects or prototypes\n",
    "\n",
    "**Example (DuckDB backend):**\n",
    "\n",
    "```python\n",
    "client = chromadb.Client(Settings(\n",
    "    persist_directory=\"./chroma_data\",\n",
    "    chroma_db_impl=\"duckdb+parquet\"\n",
    "))\n",
    "```\n",
    "\n",
    "* `chroma_db_impl` controls the storage engine.\n",
    "\n",
    "---\n",
    "\n",
    "c. Data Durability and Recovery\n",
    "\n",
    "* **Durability:** Persisted collections remain safe even after crashes or restarts.\n",
    "* **Recovery:** Simply initialize Chroma DB with the same `persist_directory` to reload collections:\n",
    "\n",
    "```python\n",
    "client = chromadb.Client(Settings(\n",
    "    persist_directory=\"./chroma_data\"\n",
    "))\n",
    "# All previous collections are restored\n",
    "print(client.list_collections())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**2. Indexing and Retrieval**\n",
    "\n",
    "Efficient retrieval of vectors requires proper **indexing**.\n",
    "\n",
    "a. Introduction to HNSW Indexing\n",
    "\n",
    "* Chroma DB uses **HNSW (Hierarchical Navigable Small World)** graphs for fast similarity search.\n",
    "* HNSW allows **approximate nearest neighbor search** in high-dimensional vector spaces with high performance.\n",
    "* Index parameters can be configured for speed vs. accuracy trade-offs (e.g., `M` and `ef_construction`).\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(\"my_collection\", metadata={}, get_or_create=True)\n",
    "# HNSW indexing is enabled by default\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "b. Performing Similarity Searches\n",
    "\n",
    "* **Querying by embedding vector** finds documents closest in semantic space:\n",
    "\n",
    "```python\n",
    "query_vector = [0.1, 0.2, 0.3]\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_vector],\n",
    "    n_results=2\n",
    ")\n",
    "print(results)\n",
    "```\n",
    "\n",
    "* `n_results`: Number of closest documents to return\n",
    "* Returned results include document IDs, content, embeddings, and metadata\n",
    "\n",
    "---\n",
    "\n",
    "c. Filtering and Querying Documents\n",
    "\n",
    "* Filters allow restricting searches based on **metadata**:\n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_embeddings=[[0.1, 0.2, 0.3]],\n",
    "    n_results=2,\n",
    "    where={\"type\": \"greeting\"}  # metadata filter\n",
    ")\n",
    "```\n",
    "\n",
    "* **Advanced filtering:** Combine multiple conditions on metadata for more precise queries.\n",
    "* You can also query **without embeddings** using metadata alone:\n",
    "\n",
    "```python\n",
    "results = collection.get(where={\"type\": \"greeting\"})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Feature            | Description                     | Example                                                   |\n",
    "| ------------------ | ------------------------------- | --------------------------------------------------------- |\n",
    "| Persist Directory  | Stores collections/data on disk | `Settings(persist_directory=\"./data\")`                    |\n",
    "| Storage Backends   | DuckDB, SQLite                  | `chroma_db_impl=\"duckdb+parquet\"`                         |\n",
    "| Durability         | Data persists across restarts   | `client.persist()`                                        |\n",
    "| HNSW Index         | Fast similarity search          | Default in collections                                    |\n",
    "| Query by Embedding | Returns nearest neighbors       | `collection.query(query_embeddings=[[...]], n_results=3)` |\n",
    "| Metadata Filtering | Filter results using metadata   | `collection.query(where={\"type\":\"greeting\"})`             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a36856",
   "metadata": {},
   "source": [
    "### **Embedding Models and Functions in Chroma DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92653554",
   "metadata": {},
   "source": [
    "Chroma DB stores **vectors (embeddings)** rather than raw data, so integrating with the right embedding model is crucial for meaningful similarity search.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Integrating with External Embedding Models**\n",
    "\n",
    "Chroma DB can work with **any embedding model** that converts raw data (text, images, audio) into numeric vectors.\n",
    "\n",
    "a. OpenAI Embeddings\n",
    "\n",
    "* OpenAI provides text embeddings via models like `text-embedding-3-large` and `text-embedding-3-small`.\n",
    "* Example integration:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "\n",
    "# Create Chroma DB embedding function using OpenAI\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=\"YOUR_OPENAI_API_KEY\",\n",
    "    model_name=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# Assign embedding function to collection\n",
    "collection = chromadb.Client().create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=openai_ef\n",
    ")\n",
    "```\n",
    "\n",
    "b. Hugging Face Models\n",
    "\n",
    "* Hugging Face provides transformer-based models for embeddings (e.g., `sentence-transformers/all-MiniLM-L6-v2`).\n",
    "* Integration example:\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "hf_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name_or_path='all-MiniLM-L6-v2')\n",
    "\n",
    "collection = chromadb.Client().create_collection(\n",
    "    name=\"hf_collection\",\n",
    "    embedding_function=hf_ef\n",
    ")\n",
    "```\n",
    "\n",
    "c. Custom Embedding Models\n",
    "\n",
    "* You can use your own models trained on specific data.\n",
    "* Any model that takes raw input and returns a **fixed-size vector** can be used:\n",
    "\n",
    "```python\n",
    "def custom_embedding_fn(texts):\n",
    "    # Example: returns 3-dimensional dummy embeddings\n",
    "    return [[len(t), len(t.split()), sum(ord(c) for c in t) % 100] for t in texts]\n",
    "\n",
    "collection = chromadb.Client().create_collection(\n",
    "    name=\"custom_collection\",\n",
    "    embedding_function=custom_embedding_fn\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**2. Using Embedding Functions**\n",
    "\n",
    "Embedding functions in Chroma DB abstract away the **vector generation step**:\n",
    "\n",
    "* When adding documents:\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=[\"Hello world\", \"Chroma DB rocks!\"],\n",
    "    ids=[\"1\", \"2\"]\n",
    ")  # embeddings are automatically computed via embedding_function\n",
    "```\n",
    "\n",
    "* When querying:\n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_texts=[\"Hello!\"],  # embedding function converts text to vector\n",
    "    n_results=1\n",
    ")\n",
    "```\n",
    "\n",
    "* Using embedding functions ensures **consistency between storage and queries**.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Fine-Tuning Embeddings for Specific Tasks**\n",
    "\n",
    "Fine-tuning embeddings improves performance for **domain-specific tasks**, such as legal, medical, or technical documents.\n",
    "\n",
    "**Strategies:**\n",
    "\n",
    "1. **Task-Specific Pretrained Models:**\n",
    "\n",
    "   * Use domain-specific models from Hugging Face or OpenAI fine-tuned models.\n",
    "\n",
    "2. **Custom Fine-Tuning:**\n",
    "\n",
    "   * Train your model on labeled pairs or triplets (contrastive learning) for your dataset.\n",
    "\n",
    "3. **Embedding Normalization:**\n",
    "\n",
    "   * Normalize vectors to unit length for **cosine similarity**.\n",
    "\n",
    "4. **Metadata-Aware Embeddings:**\n",
    "\n",
    "   * Combine embeddings with metadata features to enhance retrieval relevance.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def normalized_embedding_fn(texts):\n",
    "    vectors = custom_embedding_fn(texts)\n",
    "    return [list(np.array(v)/np.linalg.norm(v)) for v in vectors]\n",
    "\n",
    "collection = chromadb.Client().create_collection(\n",
    "    name=\"fine_tuned_collection\",\n",
    "    embedding_function=normalized_embedding_fn\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Topic                    | Key Points                                                             |\n",
    "| ------------------------ | ---------------------------------------------------------------------- |\n",
    "| OpenAI Integration       | Use `OpenAIEmbeddingFunction` to generate embeddings automatically     |\n",
    "| Hugging Face Integration | Use `SentenceTransformerEmbeddingFunction` or similar                  |\n",
    "| Custom Models            | Any function that returns numeric vectors can be used                  |\n",
    "| Embedding Functions      | Automate vector creation during add/query operations                   |\n",
    "| Fine-Tuning              | Use task-specific models, normalize embeddings, or train custom models |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974691e",
   "metadata": {},
   "source": [
    "### **Metadata and Filtering in Chroma DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6001d7",
   "metadata": {},
   "source": [
    "Chroma DB allows you to attach **metadata** to your documents and use it for **filtered queries**, which is essential for narrowing down search results and organizing your vector data effectively.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Associating Metadata with Documents**\n",
    "\n",
    "Metadata is **additional information** stored alongside each document. It is typically structured as **key-value pairs** and can include any descriptive information such as tags, source, type, category, or timestamp.\n",
    "\n",
    "Example: Adding Documents with Metadata\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"Introduction to Chroma DB\",\n",
    "        \"Using embeddings in vector databases\"\n",
    "    ],\n",
    "    embeddings=[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n",
    "    metadatas=[\n",
    "        {\"category\": \"tutorial\", \"level\": \"beginner\"},\n",
    "        {\"category\": \"tutorial\", \"level\": \"intermediate\"}\n",
    "    ],\n",
    "    ids=[\"doc1\", \"doc2\"]\n",
    ")\n",
    "```\n",
    "\n",
    "* `metadatas` is a list of dictionaries matching each document.\n",
    "* Metadata enables **filtered queries** without relying solely on embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Querying Based on Metadata**\n",
    "\n",
    "Chroma DB supports querying documents based on metadata filters using the `where` parameter.\n",
    "\n",
    "Example: Filter by Metadata\n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_embeddings=[[0.1, 0.2, 0.3]],\n",
    "    n_results=1,\n",
    "    where={\"level\": \"beginner\"}\n",
    ")\n",
    "print(results)\n",
    "```\n",
    "\n",
    "* Only documents with `level` = `\"beginner\"` will be considered in the similarity search.\n",
    "* Useful for combining **semantic search with structured filtering**.\n",
    "\n",
    "Example: Retrieving Documents Without Embeddings\n",
    "\n",
    "```python\n",
    "docs = collection.get(where={\"category\": \"tutorial\"})\n",
    "print(docs)\n",
    "```\n",
    "\n",
    "* Retrieves all documents matching metadata filters.\n",
    "* Does not require embedding-based similarity search.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Advanced Filtering Techniques**\n",
    "\n",
    "Chroma DB supports more **complex filtering** using multiple conditions:\n",
    "\n",
    "a. Multiple Metadata Conditions\n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_embeddings=[[0.4, 0.5, 0.6]],\n",
    "    n_results=2,\n",
    "    where={\"category\": \"tutorial\", \"level\": \"intermediate\"}\n",
    ")\n",
    "```\n",
    "\n",
    "* Documents must match **all conditions** in the `where` dictionary.\n",
    "\n",
    "b. Range Queries (numeric metadata)\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=[\"Advanced AI tutorial\"],\n",
    "    embeddings=[[0.7, 0.8, 0.9]],\n",
    "    metadatas=[{\"difficulty\": 8}],\n",
    "    ids=[\"doc3\"]\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[[0.7, 0.8, 0.9]],\n",
    "    n_results=1,\n",
    "    where={\"difficulty\": {\"$gt\": 5}}  # difficulty greater than 5\n",
    ")\n",
    "```\n",
    "\n",
    "* Use operators like `$gt` (greater than), `$lt` (less than), `$gte`, `$lte`.\n",
    "\n",
    "### c. Combining Metadata Filters and Similarity Search\n",
    "\n",
    "* Filters refine the **search space** for embeddings.\n",
    "* Helps **prioritize relevance** while respecting metadata constraints.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Feature                    | Description                                           | Example                                                                |\n",
    "| -------------------------- | ----------------------------------------------------- | ---------------------------------------------------------------------- |\n",
    "| Metadata                   | Key-value pairs attached to each document             | `{\"category\": \"tutorial\", \"level\": \"beginner\"}`                        |\n",
    "| Simple Filtering           | Retrieve documents matching metadata                  | `collection.get(where={\"category\": \"tutorial\"})`                       |\n",
    "| Filtered Similarity Search | Combine embeddings with metadata filters              | `collection.query(query_embeddings=[...], where={\"level\":\"beginner\"})` |\n",
    "| Advanced Filtering         | Multiple conditions, range queries, numeric operators | `{\"difficulty\":{\"$gt\":5}}`                                             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf2ea9",
   "metadata": {},
   "source": [
    "**Performance Optimization in Chroma DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcb979",
   "metadata": {},
   "source": [
    "Chroma DB is designed for high-performance vector search, but **optimizing performance** becomes critical as dataset size grows. This section covers tuning, indexing strategies, and scaling considerations.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Tuning for Large-Scale Datasets**\n",
    "\n",
    "Large datasets require careful configuration to maintain **low-latency queries** and efficient storage.\n",
    "\n",
    "a. Memory and Disk Considerations\n",
    "\n",
    "* Keep frequently queried collections in memory for faster access.\n",
    "* Use a **persistent directory** for durability and disk-backed storage.\n",
    "* Monitor memory usage to avoid excessive swapping.\n",
    "\n",
    "b. Batch Operations\n",
    "\n",
    "* **Add documents in batches** rather than one by one to reduce overhead:\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=batch_docs,\n",
    "    embeddings=batch_embeddings,\n",
    "    metadatas=batch_metadata,\n",
    "    ids=batch_ids\n",
    ")\n",
    "```\n",
    "\n",
    "* **Query multiple vectors at once** rather than issuing multiple single queries:\n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_embeddings=batch_query_vectors,\n",
    "    n_results=5\n",
    ")\n",
    "```\n",
    "\n",
    "c. Embedding Optimization\n",
    "\n",
    "* Use **lower-dimensional embeddings** if accuracy allows (reduces storage and speeds up search).\n",
    "* Normalize embeddings to improve **cosine similarity search efficiency**.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Indexing Strategies**\n",
    "\n",
    "Indexing determines **how efficiently nearest neighbors are retrieved**.\n",
    "\n",
    "a. HNSW (Hierarchical Navigable Small World)\n",
    "\n",
    "* Default index type in Chroma DB for vector search.\n",
    "* **Key parameters:**\n",
    "\n",
    "  * `M` â†’ Maximum number of neighbors per node (trade-off between speed and accuracy).\n",
    "  * `ef_construction` â†’ Higher values improve accuracy at the cost of slower indexing.\n",
    "* Example:\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(\n",
    "    \"optimized_collection\",\n",
    "    metadata={},\n",
    "    get_or_create=True\n",
    ")\n",
    "```\n",
    "\n",
    "* **Querying parameters:**\n",
    "\n",
    "  * `ef` â†’ Controls the number of candidates considered during search (higher = more accurate).\n",
    "\n",
    "b. Hybrid Indexing\n",
    "\n",
    "* Combine **metadata filtering** with vector search to reduce the search space.\n",
    "* Example: Filter on a category before performing HNSW search.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Scaling with Distributed Systems**\n",
    "\n",
    "For **enterprise-scale workloads**, you may need to distribute Chroma DB or embed it into a larger pipeline.\n",
    "\n",
    "a. Sharding\n",
    "\n",
    "* Split large collections into multiple **shards** based on metadata or document type.\n",
    "* Each shard can be queried independently and results merged.\n",
    "\n",
    "b. Replication\n",
    "\n",
    "* Maintain multiple copies of collections for **high availability** and **load balancing**.\n",
    "\n",
    "c. Integration with Orchestrators\n",
    "\n",
    "* Use **distributed orchestration frameworks** (e.g., Kubernetes, Airflow) to manage large-scale indexing, persistence, and querying.\n",
    "* Store embeddings in distributed storage (DuckDB + Parquet, S3) for **scalable persistence**.\n",
    "\n",
    "d. Approximate Nearest Neighbor (ANN) Trade-offs\n",
    "\n",
    "* HNSW is **approximate**, so you can tune parameters to balance **query speed vs. accuracy**.\n",
    "* Large datasets benefit from **lower `ef` during queries for speed** and higher `ef_construction` during indexing for accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Summary of Performance Tips**\n",
    "\n",
    "| Optimization Area      | Techniques                                                              |\n",
    "| ---------------------- | ----------------------------------------------------------------------- |\n",
    "| Memory & Storage       | Keep hot collections in memory, use persistent directory for durability |\n",
    "| Batch Operations       | Add/query in batches to reduce overhead                                 |\n",
    "| Embeddings             | Use lower dimensions if possible, normalize embeddings                  |\n",
    "| Indexing               | Tune HNSW parameters: `M`, `ef_construction`, `ef`                      |\n",
    "| Filtering              | Use metadata filters to reduce search space                             |\n",
    "| Sharding & Replication | Split large collections, replicate for availability                     |\n",
    "| Distributed Systems    | Integrate with orchestration frameworks and distributed storage         |\n",
    "| ANN Trade-offs         | Adjust search parameters to balance speed and accuracy                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef8489a",
   "metadata": {},
   "source": [
    "### **Integrating Chroma DB with LangChain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb0de6",
   "metadata": {},
   "source": [
    "Chroma DB is a natural fit for **Retrieval-Augmented Generation (RAG)** pipelines, where vector search enhances language model responses with relevant contextual data.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Overview of RAG (Retrieval-Augmented Generation)**\n",
    "\n",
    "**RAG** combines:\n",
    "\n",
    "1. **Retrieval:** Fetch relevant documents from a knowledge base or vector store.\n",
    "2. **Generation:** Use a language model (LLM) to generate responses based on retrieved documents.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Provides contextually accurate answers.\n",
    "* Reduces hallucinations by grounding the LLM with real data.\n",
    "* Scales easily with your knowledge base.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Setting Up Chroma DB with LangChain**\n",
    "\n",
    "a. Install Dependencies\n",
    "\n",
    "```bash\n",
    "pip install chromadb langchain openai\n",
    "```\n",
    "\n",
    "b. Initialize Chroma Client and Collection\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings(persist_directory=\"./chroma_data\"))\n",
    "\n",
    "collection = client.get_collection(\"my_collection\")  # or create_collection(...)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**3. Integrating with Embedding Functions**\n",
    "\n",
    "LangChain requires an **embedding function** compatible with your vector store:\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_fn = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "```\n",
    "\n",
    "* Chroma DB collections can use the same embedding function for **document addition** and **querying**.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Building a RAG Pipeline**\n",
    "\n",
    "LangChain provides a **RetrievalQA** chain that connects Chroma DB (vector store) with LLMs:\n",
    "\n",
    "a. Create a Chroma DB Retriever\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding_function=embedding_fn,\n",
    "    persist_directory=\"./chroma_data\"\n",
    ")\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})  # fetch top 3 relevant docs\n",
    "```\n",
    "\n",
    "b. Connect Retriever to an LLM\n",
    "\n",
    "```python\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True  # optional: returns docs used for answers\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "c. Querying the RAG Pipeline\n",
    "\n",
    "```python\n",
    "query = \"Explain the core concepts of Chroma DB\"\n",
    "result = qa_chain.run(query)\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "* The **retriever** fetches relevant documents from Chroma DB.\n",
    "* The **LLM** generates an answer grounded in the retrieved documents.\n",
    "\n",
    "d. Accessing Source Documents\n",
    "\n",
    "```python\n",
    "result = qa_chain({\"query\": query})\n",
    "answer = result[\"result\"]\n",
    "sources = result[\"source_documents\"]\n",
    "```\n",
    "\n",
    "* Useful for **citation, debugging, or displaying retrieved context**.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Best Practices for RAG Pipelines**\n",
    "\n",
    "1. **Keep embedding models consistent:** Ensure embeddings used in Chroma DB match the embedding function used by the retriever.\n",
    "2. **Tune `k` in search_kwargs:** Balance between context size and retrieval relevance.\n",
    "3. **Filter with metadata:** Narrow retrieval results based on categories, timestamps, or document types.\n",
    "4. **Persist collections:** Ensure the vector store persists across sessions for continuity.\n",
    "5. **Batch document ingestion:** Improves indexing speed for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Component          | Role                                        | Example                                            |\n",
    "| ------------------ | ------------------------------------------- | -------------------------------------------------- |\n",
    "| Chroma DB          | Vector store for embeddings                 | `collection.add(...)`                              |\n",
    "| Embedding Function | Converts text to vector                     | `OpenAIEmbeddings(model=\"text-embedding-3-large\")` |\n",
    "| Retriever          | Fetches top-k relevant docs                 | `vectordb.as_retriever(search_kwargs={\"k\":3})`     |\n",
    "| LLM                | Generates answer based on retrieved context | `ChatOpenAI(model=\"gpt-4\")`                        |\n",
    "| RetrievalQA        | RAG chain combining retriever + LLM         | `RetrievalQA.from_chain_type(...)`                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91914bc1",
   "metadata": {},
   "source": [
    "### **How Chroma DB Works**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456d701",
   "metadata": {},
   "source": [
    "Chroma DB is designed as a **high-performance vector database** optimized for similarity search, semantic retrieval, and AI-driven pipelines. Understanding its internal architecture and algorithms helps optimize usage and design better systems.\n",
    "\n",
    "**1. Core Architecture**\n",
    "\n",
    "Chroma DB consists of the following main components:\n",
    "\n",
    "a. Client Layer\n",
    "\n",
    "* The **interface** for applications to interact with Chroma DB.\n",
    "* Provides APIs to:\n",
    "\n",
    "  * Create and manage collections\n",
    "  * Add and query documents\n",
    "  * Perform filtering and metadata operations\n",
    "* Examples: Python SDK, REST API (planned/experimental)\n",
    "\n",
    "b. Collection Layer\n",
    "\n",
    "* Each **collection** is a logical container for:\n",
    "\n",
    "  * **Embeddings (vectors)**\n",
    "  * **Documents (raw data or content references)**\n",
    "  * **Metadata (key-value pairs)**\n",
    "* Collections isolate datasets and support multi-tenancy.\n",
    "\n",
    "c. Storage Layer\n",
    "\n",
    "* Persistent storage backend for vectors and metadata:\n",
    "\n",
    "  * **DuckDB + Parquet** (default for production-scale storage)\n",
    "  * **SQLite** (lightweight option)\n",
    "* Supports **disk persistence** and **recovery** after crashes.\n",
    "\n",
    "d. Index Layer\n",
    "\n",
    "* Responsible for fast nearest-neighbor search.\n",
    "* Uses **Hierarchical Navigable Small World (HNSW) graphs** for vector indexing.\n",
    "\n",
    "e. Query & Retrieval Layer\n",
    "\n",
    "* Handles **similarity search** and **filtered retrieval**.\n",
    "* Supports:\n",
    "\n",
    "  * k-nearest neighbor search (k-NN)\n",
    "  * Metadata-based filtering\n",
    "  * Hybrid queries (embedding + metadata)\n",
    "\n",
    "---\n",
    "\n",
    "**2. How Data Flows in Chroma DB**\n",
    "\n",
    "1. **Document ingestion**:\n",
    "\n",
    "   * Raw data â†’ Embedding function â†’ Vector\n",
    "   * Add vectors + metadata to a collection\n",
    "2. **Indexing**:\n",
    "\n",
    "   * HNSW index updates to include new vectors\n",
    "3. **Querying**:\n",
    "\n",
    "   * Input query â†’ Embedding function â†’ Query vector\n",
    "   * HNSW index searches nearest neighbors\n",
    "   * Metadata filters narrow search results\n",
    "4. **Result Retrieval**:\n",
    "\n",
    "   * Return top-k documents + embeddings + metadata\n",
    "   * Can be fed into downstream applications (RAG, recommendation, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "**3. Vector Storage and Representation**\n",
    "\n",
    "* Vectors are stored in **dense numerical arrays**, typically float32.\n",
    "* Each vector is associated with:\n",
    "\n",
    "  * **Document content** (optional)\n",
    "  * **ID** (unique identifier)\n",
    "  * **Metadata** (key-value pairs)\n",
    "\n",
    "Persistent Storage\n",
    "\n",
    "* Chroma DB serializes vectors and metadata into **Parquet files (via DuckDB)** or SQLite tables.\n",
    "* Supports **incremental persistence** with `client.persist()`.\n",
    "\n",
    "---\n",
    "**4. Indexing Mechanism: HNSW**\n",
    "\n",
    "**HNSW (Hierarchical Navigable Small World)** is the primary algorithm for nearest neighbor search:\n",
    "\n",
    "Key Concepts\n",
    "\n",
    "* Builds a **multi-layered graph** where nodes represent vectors.\n",
    "* **Top layer**: Sparse graph with long-range connections for fast approximate search.\n",
    "* **Bottom layer**: Dense graph for precise local neighbor search.\n",
    "\n",
    "Parameters\n",
    "\n",
    "* `M`: Maximum number of links per node; higher M â†’ better accuracy, more memory.\n",
    "* `ef_construction`: Controls graph construction quality; higher â†’ more accurate index.\n",
    "* `ef` (query-time): Number of candidates explored during search; higher â†’ slower but more accurate.\n",
    "\n",
    "Search Algorithm\n",
    "\n",
    "1. Start from the top layer and find closest node to query vector.\n",
    "2. Navigate through layers using greedy search.\n",
    "3. Reach bottom layer and perform **refined k-NN search**.\n",
    "\n",
    "* **Advantages**:\n",
    "\n",
    "  * Logarithmic search complexity for large datasets\n",
    "  * High accuracy with approximate nearest neighbors\n",
    "  * Incremental updates without rebuilding the entire index\n",
    "\n",
    "---\n",
    "\n",
    "**5. Metadata Filtering and Hybrid Search**\n",
    "\n",
    "* Metadata allows **structured filtering** alongside vector search.\n",
    "* During retrieval:\n",
    "\n",
    "  * First, filter vectors by metadata\n",
    "  * Then, perform HNSW k-NN search on the filtered subset\n",
    "* Supports **complex filtering**: multiple conditions, range queries, boolean combinations.\n",
    "\n",
    "---\n",
    "\n",
    "**6. Embedding Functions and Model Integration**\n",
    "\n",
    "* Chroma DB is **model-agnostic**: any embedding function that outputs fixed-size numeric vectors can be used.\n",
    "* Typical integration workflow:\n",
    "\n",
    "  * Text/Image â†’ Embedding function (OpenAI, Hugging Face, custom) â†’ Vector â†’ Chroma DB\n",
    "* Embeddings can be normalized for **cosine similarity** or used directly for **Euclidean distance**.\n",
    "\n",
    "---\n",
    "\n",
    "**7. Persistence, Durability, and Recovery**\n",
    "\n",
    "* **Persistent directory** stores collections and indices.\n",
    "* On restart, Chroma DB reloads vectors and indexes from disk.\n",
    "* Supports **incremental persistence**, enabling high durability for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "**8. Scaling Considerations**\n",
    "\n",
    "a. Sharding\n",
    "\n",
    "* Split collections into smaller **logical shards** for distributed querying.\n",
    "\n",
    "b. Replication\n",
    "\n",
    "* Duplicate collections for **high availability** and **load balancing**.\n",
    "\n",
    "c. Distributed Storage\n",
    "\n",
    "* Leverage **DuckDB + Parquet on shared storage** for large-scale deployments.\n",
    "\n",
    "d. Batch Operations\n",
    "\n",
    "* Adding/querying in batches improves indexing speed and reduces memory overhead.\n",
    "\n",
    "---\n",
    "\n",
    "**9. Summary of Chroma DB Architecture**\n",
    "\n",
    "| Layer              | Function                     | Notes                          |\n",
    "| ------------------ | ---------------------------- | ------------------------------ |\n",
    "| Client             | API interface                | Python SDK, REST API           |\n",
    "| Collection         | Logical container            | Stores vectors, docs, metadata |\n",
    "| Storage            | Persistent backend           | DuckDB + Parquet, SQLite       |\n",
    "| Index              | HNSW nearest neighbor        | Efficient approximate k-NN     |\n",
    "| Query              | Retrieval + filtering        | Embeddings + metadata          |\n",
    "| Embedding Function | Converts raw data to vectors | OpenAI, Hugging Face, custom   |\n",
    "| Scaling            | Sharding & replication       | For large datasets             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d8e49",
   "metadata": {},
   "source": [
    "# **Additional Notes - LangChain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fb312",
   "metadata": {},
   "source": [
    "## **Introduction and Fundamentals**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2eea19",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Introduction to LangChain**\n",
    "LangChain is a framework designed to simplify the **development of applications using large language models (LLMs)**. It provides tools for building pipelines that combine LLMs, retrieval systems, prompts, and memory.\n",
    "\n",
    "**What is LangChain?**\n",
    "LangChain is a Python-based framework that allows developers to **orchestrate LLMs**, integrate external data sources, and create intelligent workflows that go beyond basic text generation.\n",
    "\n",
    "**History and Evolution**\n",
    "\n",
    "* Released to address the need for structured LLM applications.\n",
    "* Evolved from simple LLM wrappers to a **comprehensive ecosystem** for building RAG systems, conversational agents, and AI workflows.\n",
    "* Constantly expanding with new connectors, memory modules, and evaluation tools.\n",
    "\n",
    "**Use Cases and Applications**\n",
    "\n",
    "* Retrieval-Augmented Generation (RAG) systems\n",
    "* Conversational AI agents\n",
    "* Knowledge management and semantic search\n",
    "* Summarization, question answering, and data analysis\n",
    "* Automation and workflow orchestration using LLMs\n",
    "\n",
    "**Architecture Overview**\n",
    "LangChainâ€™s architecture consists of modular components that can be combined to create complex pipelines:\n",
    "\n",
    "* **LLMs and Embeddings:** Core AI engines for generating text and creating vector representations\n",
    "* **Chains:** Sequences of operations executed in order\n",
    "* **Agents:** Decision-making entities that choose actions dynamically\n",
    "* **Tools:** External utilities or APIs integrated into chains\n",
    "* **Memory:** Persistent or session-based storage for conversational context\n",
    "\n",
    "**Core Concepts**\n",
    "\n",
    "**Chains, Agents, and Tools**\n",
    "\n",
    "* **Chains:** Linear or branched sequences of LLM calls or operations\n",
    "* **Agents:** Components that decide which action to take based on user input\n",
    "* **Tools:** External resources or functions that agents can call (e.g., calculators, APIs, vector stores)\n",
    "\n",
    "**Prompts and Prompt Templates**\n",
    "\n",
    "* **Prompts:** Input text templates sent to LLMs\n",
    "* **Prompt Templates:** Parameterized prompts allowing dynamic insertion of variables and context\n",
    "\n",
    "**LLMs (Large Language Models) and Embeddings**\n",
    "\n",
    "* **LLMs:** Models like GPT-4, LLaMA, or ChatOpenAI that generate text or complete tasks\n",
    "* **Embeddings:** Vector representations of text or data used for similarity search, retrieval, and semantic operations\n",
    "\n",
    "**Memory in LangChain**\n",
    "\n",
    "* Stores conversational context or intermediate results\n",
    "* Types of memory:\n",
    "\n",
    "  * **Conversation Buffer Memory:** Keeps the last few exchanges\n",
    "  * **Key-Value Memory:** Stores data for retrieval across sessions\n",
    "  * **Summary Memory:** Condenses previous interactions into a summary\n",
    "\n",
    "**Setting Up the Environment**\n",
    "\n",
    "**Installing LangChain**\n",
    "\n",
    "```bash\n",
    "pip install langchain\n",
    "```\n",
    "\n",
    "**Dependencies and Virtual Environments**\n",
    "\n",
    "* Use **virtual environments** to manage dependencies:\n",
    "\n",
    "```bash\n",
    "python -m venv env\n",
    "source env/bin/activate  # Linux/Mac\n",
    "env\\Scripts\\activate     # Windows\n",
    "```\n",
    "\n",
    "* Install required libraries like `openai`, `chromadb`, `huggingface_hub` as needed:\n",
    "\n",
    "```bash\n",
    "pip install openai chromadb huggingface_hub\n",
    "```\n",
    "\n",
    "**Configuring API Keys (OpenAI, Hugging Face, etc.)**\n",
    "\n",
    "* **OpenAI:**\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"your_api_key_here\"   # Linux/Mac\n",
    "setx OPENAI_API_KEY \"your_api_key_here\"    # Windows\n",
    "```\n",
    "\n",
    "* **Hugging Face:**\n",
    "\n",
    "```bash\n",
    "export HUGGINGFACEHUB_API_TOKEN=\"your_token_here\"\n",
    "```\n",
    "\n",
    "* Verify keys are accessible in your Python scripts:\n",
    "\n",
    "```python\n",
    "import os\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "```\n",
    "\n",
    "This setup ensures LangChain can interact with **LLMs, embeddings, and external tools** effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728c4d8",
   "metadata": {},
   "source": [
    "## **Prompt Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822974df",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Prompt Engineering** is the practice of designing and refining the input text (prompts) you give to a language model to get **accurate, relevant, and useful outputs**. Good prompt engineering is crucial for ensuring LLMs behave as expected.\n",
    "\n",
    "---\n",
    "\n",
    "**Simple vs. Complex Prompts**\n",
    "\n",
    "Language models can respond differently depending on how prompts are structured.\n",
    "\n",
    "| Type               | Description                                                                                                                      | Example                                                                                                                          |\n",
    "| ------------------ | -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Simple Prompt**  | Short and direct input, often a single question or instruction.                                                                  | `\"Translate 'Hello' to French.\"`                                                                                                 |\n",
    "| **Complex Prompt** | Includes multiple instructions, context, examples, or conditions. Often used for tasks requiring reasoning or structured output. | `\"You are a helpful assistant. Translate 'Hello' to French, provide a formal and informal version, and explain the difference.\"` |\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* **Simple prompts** are easier for beginners but may produce inconsistent results for complex tasks.\n",
    "* **Complex prompts** guide the model more precisely, improving accuracy for multi-step or structured tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**Templates and Variables**\n",
    "\n",
    "Prompt templates allow you to **reuse prompts dynamically** by inserting variables.\n",
    "\n",
    "* **Template Example:**\n",
    "\n",
    "```text\n",
    "Summarize the following text in one sentence: {text}\n",
    "```\n",
    "\n",
    "* **Python Usage with LangChain:**\n",
    "\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Summarize the following text in one sentence: {text}\"\n",
    ")\n",
    "\n",
    "prompt_text = template.format(text=\"LangChain simplifies building LLM applications.\")\n",
    "print(prompt_text)\n",
    "```\n",
    "\n",
    "**Benefits of Using Templates:**\n",
    "\n",
    "* Avoids rewriting prompts repeatedly\n",
    "* Ensures consistency across multiple queries\n",
    "* Makes prompts dynamic and adaptable to different inputs\n",
    "\n",
    "---\n",
    "\n",
    "**Few-Shot and Zero-Shot Prompting**\n",
    "\n",
    "These techniques help the model understand the task better by providing examples or relying on instructions only.\n",
    "\n",
    "| Technique               | Description                                                                     | Example                                                                                            |\n",
    "| ----------------------- | ------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |\n",
    "| **Zero-Shot Prompting** | You provide **only the task description**; the model must infer how to respond. | `\"Translate 'Good morning' to Spanish.\"`                                                           |\n",
    "| **Few-Shot Prompting**  | You provide **a few examples along with the task** to guide the model.          | `\"English: Hello â†’ Spanish: Hola\\nEnglish: Thank you â†’ Spanish: Gracias\\nEnglish: Good morning â†’\"` |\n",
    "\n",
    "**Tips for Effective Prompting:**\n",
    "\n",
    "* Start with **clear and concise instructions**\n",
    "* Include **examples for few-shot prompts** to improve accuracy\n",
    "* Specify the **format or style of output** if needed\n",
    "* Test different prompt variations to see which yields the best results\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "* Simple prompts are quick and easy; complex prompts provide better guidance.\n",
    "* Templates allow dynamic, reusable, and consistent prompts.\n",
    "* Zero-shot relies purely on instructions; few-shot improves reliability with examples.\n",
    "* Effective prompt engineering directly impacts **model performance and output quality**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659cdf02",
   "metadata": {},
   "source": [
    "## **Chains**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89e8fe",
   "metadata": {},
   "source": [
    "In LangChain, **Chains** are the fundamental building blocks for creating workflows. A chain connects multiple stepsâ€”like LLM calls, data transformations, or retrieval operationsâ€”so you can process input and generate output in a structured way.\n",
    "\n",
    "---\n",
    "\n",
    "**Simple Sequential Chains**\n",
    "\n",
    "* A **Sequential Chain** executes steps in order, passing the output of one step to the next.\n",
    "* Useful for **linear workflows** where each operation depends on the previous one.\n",
    "\n",
    "**Example:** Summarization after translation\n",
    "\n",
    "```python\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[\n",
    "        LLMChain(llm=llm, prompt=\"Translate '{text}' to French.\"),\n",
    "        LLMChain(llm=llm, prompt=\"Summarize the French text in one sentence.\")\n",
    "    ],\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"summary\"]\n",
    ")\n",
    "\n",
    "result = chain.run(text=\"LangChain simplifies building LLM applications.\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* Steps are executed **in order**\n",
    "* Output of one chain can become input for the next\n",
    "* Ideal for **linear tasks**\n",
    "\n",
    "---\n",
    "\n",
    "**LLMChain vs. SequentialChain**\n",
    "\n",
    "| Chain Type          | Description                                              | Use Case                                                     |\n",
    "| ------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |\n",
    "| **LLMChain**        | Wraps a **single LLM call** with a prompt template.      | Translation, summarization, or single-step generation tasks. |\n",
    "| **SequentialChain** | Combines **multiple chains or LLMChains** in a sequence. | Multi-step workflows like translate â†’ summarize â†’ reformat.  |\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "* **LLMChain** = single operation\n",
    "* **SequentialChain** = multiple operations chained together\n",
    "\n",
    "---\n",
    "\n",
    "**Conditional and Custom Chains**\n",
    "\n",
    "* Sometimes, workflows need **decision-making** based on input or intermediate results.\n",
    "* **Conditional Chains** allow branching using `if-else` logic or custom functions.\n",
    "* **Custom Chains** let you define your own logic for processing inputs and outputs.\n",
    "\n",
    "**Example:** Conditional chain based on input length\n",
    "\n",
    "```python\n",
    "from langchain.chains import SimpleChain\n",
    "\n",
    "def conditional_logic(inputs):\n",
    "    text = inputs[\"text\"]\n",
    "    if len(text.split()) > 10:\n",
    "        return {\"output\": f\"Long text summary: {text[:50]}...\"}\n",
    "    else:\n",
    "        return {\"output\": f\"Short text: {text}\"}\n",
    "\n",
    "custom_chain = SimpleChain(function=conditional_logic, input_variables=[\"text\"], output_variables=[\"output\"])\n",
    "result = custom_chain.run(text=\"This is a very long text example to demonstrate conditional chains in LangChain.\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* Conditional Chains = branch execution based on logic\n",
    "* Custom Chains = full control over input/output processing\n",
    "* Useful for **dynamic workflows** or **task-specific routing**\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Table of Chains in LangChain**\n",
    "\n",
    "| Chain Type            | Characteristics                              | Example                                   |\n",
    "| --------------------- | -------------------------------------------- | ----------------------------------------- |\n",
    "| **LLMChain**          | Single LLM call with prompt                  | Translate text                            |\n",
    "| **SequentialChain**   | Multiple LLMChains or operations in sequence | Translate â†’ Summarize â†’ Reformat          |\n",
    "| **Conditional Chain** | Branches execution based on conditions       | Long vs. short text processing            |\n",
    "| **Custom Chain**      | Fully custom Python logic                    | Specialized processing or transformations |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457b626",
   "metadata": {},
   "source": [
    "## **Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a0bfb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Memory in LangChain is a **mechanism to store and recall information** across multiple steps in a workflow or conversation. It is especially important in **Retrieval-Augmented Generation (RAG)** pipelines and conversational AI applications, where context and previous interactions influence responses. By maintaining memory, language models can produce **more coherent, context-aware, and accurate outputs** over time.\n",
    "\n",
    "---\n",
    "\n",
    "**Types of Memory**\n",
    "\n",
    "LangChain supports multiple types of memory, each suited for different tasks:\n",
    "\n",
    "| Memory Type                               | Description                                                                                                             | Use Case                                                                                                                                 |\n",
    "| ----------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Conversation Buffer Memory**            | Stores the last few interactions or messages in a conversation.                                                         | Short-term chat history for chatbots or assistants. Helps maintain context across recent messages.                                       |\n",
    "| **Key-Value Memory**                      | Stores information as key-value pairs that can be retrieved later.                                                      | Useful for storing structured data, such as user preferences, variables, or intermediate results in multi-step workflows.                |\n",
    "| **Summary Memory**                        | Condenses previous interactions or data into a **summarized form** to save space while retaining essential information. | Ideal for long conversations or large documents, reducing memory usage while maintaining context.                                        |\n",
    "| **Document/Vector Memory (RAG-specific)** | Stores retrieved documents or vector embeddings from external knowledge bases.                                          | Enables retrieval-augmented generation, where models answer questions based on external documents rather than just conversation context. |\n",
    "\n",
    "---\n",
    "\n",
    "**Implementing Memory in Chains**\n",
    "\n",
    "Memory in LangChain can be integrated directly into **chains**, allowing each step to access and update stored information:\n",
    "\n",
    "```python\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "# Create a prompt template that includes memory\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"user_input\"],\n",
    "    template=\"Previous conversation: {chat_history}\\nUser: {user_input}\\nAssistant:\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.5)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=template, memory=memory)\n",
    "\n",
    "# Run the chain multiple times\n",
    "response1 = chain.run(user_input=\"Hello! Who won the World Cup in 2018?\")\n",
    "response2 = chain.run(user_input=\"Can you summarize that result?\")\n",
    "```\n",
    "\n",
    "* `ConversationBufferMemory` automatically keeps track of previous exchanges.\n",
    "* Memory can be **read and updated dynamically** during the workflow.\n",
    "* Using memory in chains allows the model to **reference prior context without repeating it in every prompt manually**.\n",
    "\n",
    "---\n",
    "\n",
    "**Long-Term vs. Short-Term Memory**\n",
    "\n",
    "* **Short-Term Memory:**\n",
    "\n",
    "  * Stores immediate or recent context, often limited to the last few interactions.\n",
    "  * Examples: `ConversationBufferMemory` for chat history or a session-specific variable store.\n",
    "  * Benefits: Lightweight, fast, reduces token usage, ideal for short conversations.\n",
    "\n",
    "* **Long-Term Memory:**\n",
    "\n",
    "  * Stores information persistently across sessions or for extended periods.\n",
    "  * Examples: `SummaryMemory` or a vector database storing embeddings for RAG applications.\n",
    "  * Benefits: Maintains knowledge over time, supports complex workflows, enhances model consistency in repeated interactions.\n",
    "\n",
    "**Key Considerations:**\n",
    "\n",
    "* **Memory management is critical** for performance and relevance; storing too much can slow down chains or increase token usage.\n",
    "* **RAG systems** often combine long-term memory (external knowledge base) with short-term memory (recent conversation) for the best results.\n",
    "* Memory can also be **augmented with filtering or summarization**, ensuring that the most relevant information is used for each step.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Table: Memory Overview**\n",
    "\n",
    "| Aspect         | Short-Term Memory             | Long-Term Memory                            |\n",
    "| -------------- | ----------------------------- | ------------------------------------------- |\n",
    "| **Purpose**    | Maintain recent context       | Maintain persistent knowledge               |\n",
    "| **Examples**   | ConversationBufferMemory      | SummaryMemory, Vector store embeddings      |\n",
    "| **Scope**      | Session-specific              | Across multiple sessions                    |\n",
    "| **Advantages** | Lightweight, fast             | Retains knowledge, supports complex queries |\n",
    "| **Use Case**   | Chatbots, temporary workflows | RAG pipelines, knowledge-grounded agents    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c18b2",
   "metadata": {},
   "source": [
    "## **Documents and Text Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad225d8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Processing documents and text is a **critical part of building intelligent applications** with LangChain. This involves organizing, splitting, embedding, storing, and retrieving textual data so that large language models (LLMs) can use it effectively for tasks like summarization, question answering, or retrieval-augmented generation (RAG).\n",
    "\n",
    "---\n",
    "\n",
    "**LangChain Documents**\n",
    "\n",
    "* In LangChain, a **Document** is a standard data structure representing a piece of text along with optional metadata.\n",
    "* Metadata can include:\n",
    "\n",
    "  * Document title, author, or source URL\n",
    "  * Timestamps or creation dates\n",
    "  * Categories or tags for filtering\n",
    "* Using metadata helps organize large datasets and enables **filtered queries** in vector stores.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "from langchain.schema import Document\n",
    "\n",
    "doc = Document(\n",
    "    page_content=\"LangChain simplifies building workflows with LLMs.\",\n",
    "    metadata={\"source\": \"tutorial\", \"topic\": \"LangChain Basics\"}\n",
    ")\n",
    "```\n",
    "\n",
    "* Documents are the **primary unit** for embedding and retrieval operations.\n",
    "\n",
    "---\n",
    "\n",
    "**Text Splitters**\n",
    "\n",
    "* **Text splitting** is necessary when dealing with large documents to:\n",
    "\n",
    "  * Break text into chunks compatible with LLM token limits\n",
    "  * Preserve context across segments\n",
    "* LangChain provides multiple **text splitter classes**:\n",
    "\n",
    "  * **CharacterTextSplitter:** Splits text by character count\n",
    "  * **RecursiveCharacterTextSplitter:** Recursively splits text by paragraphs, sentences, or characters\n",
    "  * **TokenTextSplitter:** Splits text based on tokens for better LLM compatibility\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_text(long_text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Document Loaders (PDF, CSV, Webpages, etc.)**\n",
    "\n",
    "LangChain supports **loading documents from various sources**:\n",
    "\n",
    "| Loader Type                | Description                             | Example                                       |\n",
    "| -------------------------- | --------------------------------------- | --------------------------------------------- |\n",
    "| **PDFLoader**              | Loads PDF files and extracts text       | `PDFLoader(\"file.pdf\").load()`                |\n",
    "| **CSVLoader**              | Reads CSV files as structured documents | `CSVLoader(\"data.csv\").load()`                |\n",
    "| **WebBaseLoader**          | Extracts text from web pages            | `WebBaseLoader(\"https://example.com\").load()` |\n",
    "| **UnstructuredFileLoader** | Generic loader for TXT, DOCX, etc.      | `UnstructuredFileLoader(\"file.txt\").load()`   |\n",
    "\n",
    "* Loaders automatically return a **list of Documents**, ready for splitting and embedding.\n",
    "\n",
    "---\n",
    "\n",
    "**Embeddings**\n",
    "\n",
    "**What are Embeddings?**\n",
    "\n",
    "* Embeddings are **numerical vector representations of text or data**, capturing semantic meaning.\n",
    "* They allow LLMs and vector databases to perform **similarity searches**, semantic clustering, and retrieval tasks.\n",
    "\n",
    "**Using OpenAI and Hugging Face Embeddings**\n",
    "\n",
    "* **OpenAI Embeddings** example:\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector = embedding_model.embed_query(\"LangChain is powerful\")\n",
    "```\n",
    "\n",
    "* **Hugging Face Embeddings** example:\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector = embedding_model.embed_query(\"LangChain simplifies workflows\")\n",
    "```\n",
    "\n",
    "**Fine-Tuning Embeddings for Custom Tasks**\n",
    "\n",
    "* Fine-tuning embeddings allows models to better capture **domain-specific semantics**.\n",
    "* Methods include:\n",
    "\n",
    "  * Training with **domain-specific text pairs** for similarity\n",
    "  * Adjusting embedding dimensions or normalizations\n",
    "  * Using supervised or contrastive learning to improve retrieval relevance\n",
    "\n",
    "---\n",
    "\n",
    "**Vector Stores**\n",
    "\n",
    "**Introduction to Vector Databases**\n",
    "\n",
    "* Vector databases store embeddings efficiently and enable **fast similarity searches**.\n",
    "* They are optimized for **nearest neighbor queries** over large datasets.\n",
    "\n",
    "**Popular Vector Databases**\n",
    "\n",
    "| Database     | Features                            | Notes                                  |\n",
    "| ------------ | ----------------------------------- | -------------------------------------- |\n",
    "| **Chroma**   | Open-source, Python-native          | Easy integration with LangChain        |\n",
    "| **Pinecone** | Cloud-based, scalable               | Fully managed service                  |\n",
    "| **FAISS**    | Facebook AI library, local indexing | High-performance, GPU acceleration     |\n",
    "| **Weaviate** | Open-source, cloud-ready            | Supports GraphQL API                   |\n",
    "| **Milvus**   | High-performance vector DB          | Suitable for enterprise-scale datasets |\n",
    "\n",
    "**Storing and Querying Embeddings**\n",
    "\n",
    "* After generating embeddings, they are added to a vector store with optional metadata:\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=[\"LangChain simplifies LLM workflows.\"],\n",
    "    embeddings=[vector],\n",
    "    metadatas=[{\"source\": \"tutorial\"}],\n",
    "    ids=[\"doc1\"]\n",
    ")\n",
    "```\n",
    "\n",
    "* Queries return **top-k similar documents** based on vector similarity:\n",
    "\n",
    "```python\n",
    "results = collection.query(query_vector, n_results=3)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b7085",
   "metadata": {},
   "source": [
    "## **Setting up a RAG Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce0525",
   "metadata": {},
   "source": [
    "**Retrieval-Augmented Generation (RAG)** is a method where a **language model (LLM) generates answers based on retrieved documents** from a vector database. This approach allows the model to produce **accurate, contextually grounded responses** without relying solely on its internal knowledge.\n",
    "\n",
    "---\n",
    "\n",
    "**Steps to Set Up a RAG Pipeline**\n",
    "\n",
    "1. **Prepare Your Documents**\n",
    "\n",
    "   * Collect textual data from PDFs, web pages, CSVs, or plain text.\n",
    "   * Use **document loaders** and optionally **split large documents** into smaller chunks using text splitters.\n",
    "\n",
    "   ```python\n",
    "   from langchain.document_loaders import PDFLoader\n",
    "   from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "   loader = PDFLoader(\"example.pdf\")\n",
    "   documents = loader.load()\n",
    "\n",
    "   splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "   docs = splitter.split_documents(documents)\n",
    "   ```\n",
    "\n",
    "2. **Generate Embeddings**\n",
    "\n",
    "   * Convert text chunks into **vector embeddings** using OpenAI, Hugging Face, or custom models.\n",
    "\n",
    "   ```python\n",
    "   from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "   embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "   embeddings = [embedding_model.embed_query(doc.page_content) for doc in docs]\n",
    "   ```\n",
    "\n",
    "3. **Store Embeddings in a Vector Store**\n",
    "\n",
    "   * Choose a vector database like **Chroma, FAISS, Pinecone, Weaviate, or Milvus**.\n",
    "   * Add documents, embeddings, and metadata for efficient retrieval.\n",
    "\n",
    "   ```python\n",
    "   import chromadb\n",
    "   client = chromadb.Client()\n",
    "   collection = client.create_collection(\"my_docs\")\n",
    "   collection.add(documents=[doc.page_content for doc in docs], embeddings=embeddings)\n",
    "   ```\n",
    "\n",
    "4. **Set Up a Retriever**\n",
    "\n",
    "   * A retriever queries the vector store and returns **top-k relevant documents** for a user query.\n",
    "\n",
    "   ```python\n",
    "   retriever = collection.as_retriever(search_kwargs={\"k\": 5})\n",
    "   ```\n",
    "\n",
    "5. **Integrate the LLM**\n",
    "\n",
    "   * Combine the retriever with an LLM to **generate answers using the retrieved context**.\n",
    "\n",
    "   ```python\n",
    "   from langchain.chat_models import ChatOpenAI\n",
    "   from langchain.chains import RetrievalQA\n",
    "\n",
    "   llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "   rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "   ```\n",
    "\n",
    "6. **Run the RAG Pipeline**\n",
    "\n",
    "   * Input a user query and get a context-aware response:\n",
    "\n",
    "   ```python\n",
    "   query = \"Explain how LangChain handles document embeddings.\"\n",
    "   answer = rag_chain.run(query)\n",
    "   print(answer)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "**Combining LLMs with Vector Stores**\n",
    "\n",
    "* **Vector Stores** provide **retrieval capability** by returning the most semantically relevant documents.\n",
    "* **LLMs** generate answers **grounded in the retrieved documents**, reducing hallucinations and improving accuracy.\n",
    "\n",
    "**Key Benefits of LLM + Vector Store Integration:**\n",
    "\n",
    "| Feature               | Benefit                                                                                                 |\n",
    "| --------------------- | ------------------------------------------------------------------------------------------------------- |\n",
    "| Context-Aware Answers | The LLM generates responses using real documents instead of relying solely on its pretrained knowledge. |\n",
    "| Scalability           | Easily scale to large datasets by storing embeddings in vector databases.                               |\n",
    "| Flexibility           | Supports multiple data sources: PDFs, web pages, CSVs, or any text documents.                           |\n",
    "| Accuracy              | Metadata filtering and top-k retrieval improve relevance and precision.                                 |\n",
    "\n",
    "---\n",
    "\n",
    "**Tips for Optimizing RAG Pipelines:**\n",
    "\n",
    "* Use **chunked documents** to ensure the LLM receives context that fits within token limits.\n",
    "* Fine-tune **retriever parameters** like `k` or distance metric to balance accuracy and performance.\n",
    "* Include **metadata filtering** for domain-specific queries (e.g., date, category).\n",
    "* Optionally, maintain **short-term memory** for multi-turn conversations to improve continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d2745",
   "metadata": {},
   "source": [
    "## **Setting up a RAG Pipeline with LCEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab0827",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**LangChain Expression Language (LCEL)** allows you to define **RAG workflows declaratively** using a concise, chainable syntax. By combining LCEL with vector stores and LLMs, you can build a **dynamic retrieval-augmented generation pipeline** without manually orchestrating each step.\n",
    "\n",
    "**Steps to Set Up a RAG Pipeline with LCEL**\n",
    "\n",
    "1. **Prepare and Embed Documents**\n",
    "\n",
    "   * Load and split documents, then generate embeddings as usual:\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import PDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Load PDF documents\n",
    "loader = PDFLoader(\"example.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents into manageable chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "embeddings = [embedding_model.embed_query(doc.page_content) for doc in docs]\n",
    "```\n",
    "\n",
    "2. **Store Embeddings in a Vector Store**\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"my_docs\")\n",
    "collection.add(documents=[doc.page_content for doc in docs], embeddings=embeddings)\n",
    "retriever = collection.as_retriever(search_kwargs={\"k\": 5})\n",
    "```\n",
    "\n",
    "3. **Define the LCEL RAG Chain**\n",
    "\n",
    "* LCEL allows you to define a **retrieval + prompt + LLM** pipeline in a single, readable expression.\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Example custom prompt template\n",
    "custom_prompt = \"Using the context below, answer the question.\\nContext: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "# Define the LCEL chain\n",
    "rag_chain_lcel = (\n",
    "    {\n",
    "        # Retrieve relevant documents and format them\n",
    "        \"context\": retriever | (lambda docs: \"\\n\".join([d.page_content for d in docs])),\n",
    "        # Pass the user query directly\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    # Apply the custom prompt template\n",
    "    | (lambda x: custom_prompt.format(context=x[\"context\"], question=x[\"question\"]))\n",
    "    # Generate the answer using the LLM\n",
    "    | llm\n",
    "    # Parse the output into a clean string\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "4. **Run the LCEL RAG Chain**\n",
    "\n",
    "```python\n",
    "query = \"Explain how LangChain handles document embeddings.\"\n",
    "answer = rag_chain_lcel.invoke(query)\n",
    "print(answer)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**How LCEL Improves the RAG Workflow**\n",
    "\n",
    "| Feature                      | Benefit                                                                                                        |             |\n",
    "| ---------------------------- | -------------------------------------------------------------------------------------------------------------- | ----------- |\n",
    "| **Declarative Syntax**       | Define the pipeline in a concise, readable way without manually chaining functions.                            |             |\n",
    "| **Composable Steps**         | Retrieval, formatting, LLM invocation, and output parsing are easily chained with the `                        | ` operator. |\n",
    "| **Dynamic Input Handling**   | User queries are passed directly via `RunnablePassthrough()`, making it flexible for interactive applications. |             |\n",
    "| **Integration with Prompts** | Custom prompt templates can be applied dynamically to retrieved documents before generating responses.         |             |\n",
    "| **Output Parsing**           | Built-in output parsers ensure the LLM response is clean and usable.                                           |             |\n",
    "\n",
    "---\n",
    "\n",
    "**Key Tips for LCEL RAG Pipelines:**\n",
    "\n",
    "* Use **metadata filtering** in the retriever to improve relevance.\n",
    "* Chunk documents appropriately to fit within LLM token limits.\n",
    "* Combine **short-term memory** with retrieval to maintain context in multi-turn conversations.\n",
    "* Fine-tune embeddings or prompt templates for **domain-specific accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28467a5f",
   "metadata": {},
   "source": [
    "## **Agents and Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e6caa",
   "metadata": {},
   "source": [
    "Agents are a **core concept in LangChain** that allow for more dynamic and intelligent workflows compared to static chains. They act as **decision-making entities**, determining which actions to take based on user input, retrieved information, or intermediate results. Agents are particularly useful when tasks require reasoning, multi-step decision-making, or the integration of external tools.\n",
    "\n",
    "---\n",
    "\n",
    "**What are Agents?**\n",
    "\n",
    "* Agents are components that **decide what to do next** rather than just performing a predefined sequence of operations.\n",
    "* Unlike chains that execute steps linearly, agents can:\n",
    "\n",
    "  * Call different tools dynamically\n",
    "  * Handle conditional logic\n",
    "  * Iterate until a satisfactory solution is found\n",
    "* Agents are ideal for **complex workflows, question answering, or multi-turn conversations** where the model must reason about which action to take next.\n",
    "\n",
    "**Key Characteristics of Agents:**\n",
    "\n",
    "* **Autonomy:** Agents can choose the next action without human intervention.\n",
    "* **Flexibility:** They can call different tools based on context.\n",
    "* **Context-Aware:** Agents can maintain memory and use retrieved information to inform decisions.\n",
    "\n",
    "---\n",
    "\n",
    "**Types of Agents**\n",
    "\n",
    "| Agent Type               | Description                                                                                                                                               | Example Use Case                                                               |\n",
    "| ------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ |\n",
    "| **Zero-Shot Agent**      | Operates without examples, relying on instructions and prompts to decide actions.                                                                         | Quickly answering questions using only a tool description.                     |\n",
    "| **ReAct Agent**          | Combines **reasoning and action** in iterative steps. It alternates between thinking (reasoning) and acting (tool execution) until it reaches a solution. | Solving complex math problems by retrieving data and calculating step-by-step. |\n",
    "| **Conversational Agent** | Maintains context across a conversation, allowing multi-turn interactions with the user. Often integrated with memory to provide coherent responses.      | Customer support chatbot that remembers previous queries.                      |\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "* Zero-shot agents are **simpler and faster**, suitable for straightforward tasks.\n",
    "* ReAct agents are **more robust for complex problem-solving** due to their iterative reasoning.\n",
    "* Conversational agents are **optimized for dialogue**, leveraging memory and context tracking.\n",
    "\n",
    "---\n",
    "\n",
    "**Tool-Enabled Agents**\n",
    "\n",
    "* Tool-enabled agents can **access external APIs, databases, calculators, or other utilities** to perform tasks beyond the capabilities of an LLM alone.\n",
    "* Tools are registered with the agent, and the agent decides **which tool to call and when**.\n",
    "\n",
    "**Example:** Using a calculator tool in a conversational agent\n",
    "\n",
    "```python\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Define a simple calculator tool\n",
    "def calculator(input_text: str) -> str:\n",
    "    return str(eval(input_text))\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=calculator,\n",
    "        description=\"Performs arithmetic calculations\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize an LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create a tool-enabled agent\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# Run the agent with a query\n",
    "response = agent.run(\"What is 25 multiplied by 13?\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Benefits of Tool-Enabled Agents:**\n",
    "\n",
    "* Extend the capabilities of LLMs to **perform real-world tasks**.\n",
    "* Allow **dynamic decision-making**, selecting the appropriate tool based on the query.\n",
    "* Enable integration with **databases, APIs, and custom functions**, making workflows more intelligent.\n",
    "\n",
    "---\n",
    "\n",
    "**Best Practices for Using Agents:**\n",
    "\n",
    "1. **Define Clear Tool Descriptions:** Agents rely on tool descriptions to decide which to use.\n",
    "2. **Limit Token Usage in Prompts:** Large context with many tools can increase token consumption.\n",
    "3. **Use Memory for Multi-Turn Tasks:** Conversational or task-tracking agents benefit from memory integration.\n",
    "4. **Combine with RAG Pipelines:** Agents can retrieve relevant documents and then act based on the retrieved knowledge.\n",
    "5. **Monitor and Log Decisions:** For debugging, verbose logging helps understand agent reasoning and tool usage.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90059a05",
   "metadata": {},
   "source": [
    "## **Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b99221",
   "metadata": {},
   "source": [
    "In LangChain, **tools** are external utilities, APIs, or functions that an agent can leverage to perform specific tasks that go beyond the capabilities of a language model alone. Tools enable agents to **interact with the real world, perform computations, fetch external data, and execute custom workflows**, making them essential for building intelligent, dynamic AI applications.\n",
    "\n",
    "---\n",
    "\n",
    "**Integrating APIs and Functions**\n",
    "\n",
    "* Tools can be **external APIs** or **Python functions** registered with an agent.\n",
    "* Each tool typically includes:\n",
    "\n",
    "  * **Name:** The identifier used by the agent to reference the tool\n",
    "  * **Function:** The callable logic that performs the task\n",
    "  * **Description:** Explains when and how the tool should be used\n",
    "\n",
    "**Example: API Integration**\n",
    "\n",
    "```python\n",
    "from langchain.agents import Tool\n",
    "import requests\n",
    "\n",
    "def weather_api(city: str) -> str:\n",
    "    response = requests.get(f\"https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}\")\n",
    "    data = response.json()\n",
    "    return f\"The current weather in {city} is {data['current']['condition']['text']} with a temperature of {data['current']['temp_c']}Â°C.\"\n",
    "\n",
    "weather_tool = Tool(\n",
    "    name=\"WeatherChecker\",\n",
    "    func=weather_api,\n",
    "    description=\"Provides the current weather for a specified city.\"\n",
    ")\n",
    "```\n",
    "\n",
    "* Agents can dynamically select and call the API when a query requires weather information.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Makes agents **context-aware** and able to respond to real-world queries.\n",
    "* Allows integration with **any web-based service or internal API**.\n",
    "\n",
    "---\n",
    "\n",
    "**Python REPL and Custom Tool Integration**\n",
    "\n",
    "* The **Python REPL tool** enables agents to execute arbitrary Python code at runtime.\n",
    "* Useful for tasks such as:\n",
    "\n",
    "  * Mathematical computations\n",
    "  * Data transformations\n",
    "  * Dynamic logic execution\n",
    "\n",
    "**Example: Python REPL Tool**\n",
    "\n",
    "```python\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Python REPL tool\n",
    "python_tool = Tool(\n",
    "    name=\"Python REPL\",\n",
    "    func=lambda code: str(eval(code)),\n",
    "    description=\"Executes Python code and returns the result.\"\n",
    ")\n",
    "\n",
    "# Initialize an LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create an agent with Python REPL capabilities\n",
    "agent = initialize_agent(\n",
    "    tools=[python_tool],\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run an example\n",
    "result = agent.run(\"Compute 125 * 32 + 10\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "* This approach allows agents to **dynamically compute or process data** without predefining every possible operation.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Offers **flexibility** for multi-step or unpredictable workflows\n",
    "* Supports **custom logic** that can be integrated into agent reasoning\n",
    "\n",
    "---\n",
    "\n",
    "**Web Scraping and Query Tools**\n",
    "\n",
    "* Web scraping tools allow agents to **extract live data from websites** and other online sources.\n",
    "* Query tools can access **SQL, NoSQL, or other structured databases** to retrieve information dynamically.\n",
    "\n",
    "**Example: Web Scraping Tool**\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain.agents import Tool\n",
    "\n",
    "def scrape_page(url: str) -> str:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup.get_text()[:500]  # Return first 500 characters for brevity\n",
    "\n",
    "web_scraper_tool = Tool(\n",
    "    name=\"WebScraper\",\n",
    "    func=scrape_page,\n",
    "    description=\"Scrapes and returns the first 500 characters of the text from a webpage.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Example: Database Query Tool**\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "\n",
    "def query_database(query: str) -> str:\n",
    "    conn = sqlite3.connect(\"example.db\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return str(results)\n",
    "\n",
    "database_tool = Tool(\n",
    "    name=\"DatabaseQuery\",\n",
    "    func=query_database,\n",
    "    description=\"Executes SQL queries and returns results.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Provides **real-time and up-to-date information**\n",
    "* Enables agents to **perform complex lookups or data retrieval tasks**\n",
    "* Supports integration with **enterprise systems and external datasets**\n",
    "\n",
    "---\n",
    "\n",
    "**Summary of Tool Integration in LangChain**\n",
    "\n",
    "| Tool Type                | Description                               | Use Case                                                 |\n",
    "| ------------------------ | ----------------------------------------- | -------------------------------------------------------- |\n",
    "| **API Tool**             | Connects to external APIs or web services | Weather info, stock prices, translation APIs             |\n",
    "| **Python REPL Tool**     | Executes arbitrary Python code            | Computation, data transformation, dynamic logic          |\n",
    "| **Web Scraping Tool**    | Extracts content from web pages           | Research, news updates, live data extraction             |\n",
    "| **Query Tool**           | Queries databases or structured datasets  | Reporting, analytics, retrieving structured information  |\n",
    "| **Custom Function Tool** | Any Python function exposed to the agent  | Domain-specific tasks, preprocessing, or task automation |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f246d",
   "metadata": {},
   "source": [
    "## **Advanced Agent Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531af48",
   "metadata": {},
   "source": [
    "Advanced agent strategies in LangChain enable agents to **handle complex tasks, multi-step workflows, and real-world uncertainties**. By combining reasoning, planning, tool usage, and error handling, these agents become **dynamic problem solvers** capable of acting intelligently in diverse scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "**Multi-Step Reasoning**\n",
    "\n",
    "* Multi-step reasoning allows agents to **break down a complex problem into smaller, manageable steps** and solve them sequentially or iteratively.\n",
    "* Agents use reasoning to **decide which tools to call, in which order**, and how to process intermediate results.\n",
    "\n",
    "**Example:** Calculating the average temperature from multiple cities using a weather API tool\n",
    "\n",
    "```python\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Example tool: weather API\n",
    "def weather_api(city: str) -> str:\n",
    "    # Simulated API response\n",
    "    data = {\"London\": 15, \"New York\": 22, \"Tokyo\": 19}\n",
    "    return str(data.get(city, \"Data not available\"))\n",
    "\n",
    "tools = [Tool(name=\"WeatherChecker\", func=weather_api, description=\"Returns temperature of a city\")]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "query = \"Calculate the average temperature for London, New York, and Tokyo.\"\n",
    "response = agent.run(query)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Handles **multi-step workflows** automatically\n",
    "* Reduces human effort in coordinating tool calls\n",
    "* Useful for **analytics, planning, and problem-solving**\n",
    "\n",
    "---\n",
    "\n",
    "**Planning Agents**\n",
    "\n",
    "* **Planning agents** can **decompose complex tasks into sub-tasks**, execute them in sequence, and track dependencies.\n",
    "* Planning can be **explicit**, where tasks are predefined, or **dynamic**, where the agent decides on-the-fly based on input and retrieved context.\n",
    "\n",
    "**Use Cases:**\n",
    "\n",
    "* Multi-step document analysis: retrieve relevant documents â†’ extract key points â†’ summarize â†’ generate report\n",
    "* Event planning: check availability â†’ book venue â†’ send invitations â†’ confirm attendees\n",
    "\n",
    "**Example Workflow:**\n",
    "\n",
    "1. Retrieve relevant documents using a vector store\n",
    "2. Extract key insights from each document\n",
    "3. Perform calculations or transformations on the extracted data\n",
    "4. Generate a final output summary\n",
    "\n",
    "Planning agents allow **longer workflows without losing context**, making them ideal for RAG systems, report generation, and knowledge-intensive tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**Error Handling and Fallbacks**\n",
    "\n",
    "* Real-world tools and APIs may fail due to **network issues, invalid inputs, or service downtime**.\n",
    "* Agents should include **error handling and fallback strategies** to maintain robustness and reliability.\n",
    "\n",
    "**Error Handling Strategies:**\n",
    "\n",
    "1. **Try-Catch Logic:** Wrap tool calls in try-except blocks to catch runtime errors.\n",
    "2. **Fallback Tools:** Use alternative tools if the primary tool fails.\n",
    "3. **Default Responses:** Return safe or partial answers when tools cannot provide results.\n",
    "4. **Retries:** Retry failed tool calls automatically before giving up.\n",
    "\n",
    "**Example:** Robust weather API tool\n",
    "\n",
    "```python\n",
    "def safe_weather_api(city: str) -> str:\n",
    "    try:\n",
    "        # Simulated API call\n",
    "        data = {\"London\": 15, \"New York\": 22, \"Tokyo\": 19}\n",
    "        return str(data[city])\n",
    "    except KeyError:\n",
    "        return \"Weather data not available.\"\n",
    "    except Exception:\n",
    "        return \"Service currently unavailable, please try again later.\"\n",
    "```\n",
    "\n",
    "* Integrating robust error handling ensures agents remain **responsive and reliable** in production scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table: Advanced Agent Strategies\n",
    "\n",
    "| Strategy                       | Description                                                 | Benefits                                       | Example                                        |\n",
    "| ------------------------------ | ----------------------------------------------------------- | ---------------------------------------------- | ---------------------------------------------- |\n",
    "| **Multi-Step Reasoning**       | Decomposes complex tasks into sequential or iterative steps | Automates complex workflows, improves accuracy | Calculating averages from multiple data points |\n",
    "| **Planning Agents**            | Breaks tasks into sub-tasks and executes them in order      | Maintains context, handles dependencies        | Multi-document analysis and summarization      |\n",
    "| **Error Handling & Fallbacks** | Ensures resilience against tool failures or invalid inputs  | Improves reliability, avoids workflow crashes  | Retry API calls, provide default responses     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654a1d1",
   "metadata": {},
   "source": [
    "## **Advanced LangChain Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a1a1c",
   "metadata": {},
   "source": [
    "**Callbacks and Logging**\n",
    "\n",
    "Callbacks in LangChain allow you to **hook into the execution of chains, agents, or tools** to monitor activity, collect data, or trigger additional logic. Logging provides a **record of these interactions**, which is crucial for debugging, performance monitoring, and analysis.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "* **Callbacks:** Functions or objects called at specific points during execution (e.g., before a chain runs, after an LLM generates output).\n",
    "* **Logging:** Recording events, outputs, errors, or timing information.\n",
    "* **Callback Managers:** Manage multiple callbacks, ensuring they are executed in order.\n",
    "\n",
    "**Example: Using Callbacks for Logging**\n",
    "\n",
    "```python\n",
    "from langchain.callbacks import CallbackManager, StdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a callback manager\n",
    "callback_manager = CallbackManager([StdOutCallbackHandler()])\n",
    "\n",
    "# Define prompt and LLM\n",
    "prompt = PromptTemplate(input_variables=[\"topic\"], template=\"Explain {topic} in simple terms.\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", callback_manager=callback_manager, verbose=True)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "response = chain.run(\"LangChain callbacks\")\n",
    "```\n",
    "\n",
    "* The `StdOutCallbackHandler` prints logs to the console whenever the chain runs.\n",
    "* Callbacks can also be **custom-defined** to save logs to files, databases, or monitoring dashboards.\n",
    "\n",
    "---\n",
    "\n",
    "**Debugging and Monitoring Chains**\n",
    "\n",
    "LangChainâ€™s callback and logging system makes it easier to **debug complex chains and agents**:\n",
    "\n",
    "* **Track LLM Input/Output:** Monitor prompts sent to the model and responses generated.\n",
    "* **Step-by-Step Debugging:** Observe intermediate steps in sequential or conditional chains.\n",
    "* **Error Tracing:** Capture exceptions, invalid outputs, or tool failures.\n",
    "* **Performance Monitoring:** Measure time taken for each step or tool call.\n",
    "\n",
    "**Example: Custom Debugging Callback**\n",
    "\n",
    "```python\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "class DebugCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        print(\"LLM started with prompts:\", prompts)\n",
    "    \n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        print(\"LLM finished, response length:\", len(response.generations[0][0].text))\n",
    "\n",
    "# Attach custom handler\n",
    "callback_manager = CallbackManager([DebugCallbackHandler()])\n",
    "llm = ChatOpenAI(model=\"gpt-4\", callback_manager=callback_manager)\n",
    "```\n",
    "\n",
    "* This approach gives **fine-grained visibility** into model behavior and chain execution.\n",
    "\n",
    "---\n",
    "\n",
    "**Integration with MLflow and Other Tools**\n",
    "\n",
    "LangChain can integrate with **MLflow, Weights & Biases, and other monitoring or tracking platforms** to manage AI workflows in production:\n",
    "\n",
    "* **MLflow Integration:**\n",
    "\n",
    "  * Log chain inputs, outputs, metrics, and artifacts automatically.\n",
    "  * Track experiments for different prompts, models, and embeddings.\n",
    "* **Benefits:**\n",
    "\n",
    "  * Enables reproducibility\n",
    "  * Provides historical logs for analysis and optimization\n",
    "  * Supports production-grade monitoring and versioning\n",
    "\n",
    "**Example: Logging with MLflow**\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"langchain_test\"):\n",
    "    result = chain.run(\"Explain RAG pipelines\")\n",
    "    mlflow.log_param(\"topic\", \"RAG pipelines\")\n",
    "    mlflow.log_metric(\"response_length\", len(result))\n",
    "    mlflow.log_text(result, \"response.txt\")\n",
    "```\n",
    "\n",
    "* You can track multiple **chains, agents, and experiments** centrally, facilitating **continuous improvement and monitoring**.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Table: Callbacks and Monitoring**\n",
    "\n",
    "| Feature                     | Description                                            | Use Case                                             |\n",
    "| --------------------------- | ------------------------------------------------------ | ---------------------------------------------------- |\n",
    "| **Callbacks**               | Hook functions executed during chain or agent runtime  | Logging, triggering custom actions, debugging        |\n",
    "| **Logging**                 | Record inputs, outputs, errors, and timing information | Track workflows, performance, and correctness        |\n",
    "| **Debugging Handlers**      | Custom callback implementations for monitoring         | Fine-grained step-level visibility                   |\n",
    "| **MLflow / External Tools** | Track experiments, metrics, and artifacts              | Production monitoring, reproducibility, optimization |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9b027",
   "metadata": {},
   "source": [
    "## **Custom Chains and Components**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2249f4",
   "metadata": {},
   "source": [
    "**Building Reusable Chains**\n",
    "\n",
    "* **Reusable chains** are modular sequences of operations that can be invoked multiple times with different inputs.\n",
    "* Chains can combine **LLMs, tools, memory, and custom logic** into a single callable object.\n",
    "\n",
    "**Benefits of Reusable Chains:**\n",
    "\n",
    "* Avoids repetitive coding\n",
    "* Standardizes workflows for consistent results\n",
    "* Makes it easier to **scale and maintain** AI applications\n",
    "\n",
    "**Example: A Reusable QA Chain**\n",
    "\n",
    "```python\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define a prompt template\n",
    "qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"Using the context below, answer the question.\\nContext: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "# Create a reusable chain\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
    "\n",
    "# Execute the chain\n",
    "context = \"LangChain simplifies building workflows with LLMs.\"\n",
    "question = \"What is LangChain?\"\n",
    "answer = qa_chain.run(context=context, question=question)\n",
    "print(answer)\n",
    "```\n",
    "\n",
    "* This chain can be reused for multiple questions or contexts without modification.\n",
    "\n",
    "---\n",
    "\n",
    "**Custom Prompt Templates**\n",
    "\n",
    "* **Custom prompt templates** allow you to define the **format, variables, and instructions** for LLM input.\n",
    "* Templates can be simple or complex and can include:\n",
    "\n",
    "  * Conditional instructions\n",
    "  * Few-shot examples\n",
    "  * Dynamic variables from chain inputs\n",
    "\n",
    "**Example: Few-Shot Prompt Template**\n",
    "\n",
    "```python\n",
    "few_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"input_text\"],\n",
    "    template=\"\"\"\n",
    "    Translate the following English text to French:\n",
    "\n",
    "    Example:\n",
    "    English: Hello\n",
    "    French: Bonjour\n",
    "\n",
    "    English: {input_text}\n",
    "    French:\n",
    "    \"\"\"\n",
    ")\n",
    "translation_chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "output = translation_chain.run(input_text=\"How are you?\")\n",
    "print(output)\n",
    "```\n",
    "\n",
    "* Custom templates help **guide LLM behavior** and improve output consistency.\n",
    "\n",
    "---\n",
    "\n",
    "**Extending LangChain with Python**\n",
    "\n",
    "* LangChain allows you to **extend functionality using Python**, including:\n",
    "\n",
    "  * Custom chains and modules\n",
    "  * Tool definitions\n",
    "  * Preprocessing and postprocessing of data\n",
    "* Python extensions can integrate with:\n",
    "\n",
    "  * APIs, databases, and external services\n",
    "  * Custom logic for specialized workflows\n",
    "  * Automated evaluation pipelines\n",
    "\n",
    "**Example: Custom Chain Component**\n",
    "\n",
    "```python\n",
    "from langchain.chains.base import Chain\n",
    "\n",
    "class ReverseTextChain(Chain):\n",
    "    input_keys = [\"text\"]\n",
    "    output_keys = [\"reversed_text\"]\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        reversed_text = inputs[\"text\"][::-1]\n",
    "        return {\"reversed_text\": reversed_text}\n",
    "\n",
    "reverse_chain = ReverseTextChain()\n",
    "result = reverse_chain({\"text\": \"LangChain\"})\n",
    "print(result[\"reversed_text\"])  # Output: niaChgnaL\n",
    "```\n",
    "\n",
    "* This demonstrates **custom logic integration** in a reusable chain format.\n",
    "\n",
    "---\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "Evaluation in LangChain is essential to **measure the quality, accuracy, and relevance** of LLM outputs. By defining metrics and automated pipelines, you can systematically **assess performance** and improve models or prompts.\n",
    "\n",
    "---\n",
    "\n",
    "**Evaluating LLM Outputs**\n",
    "\n",
    "* LLM outputs can be evaluated based on:\n",
    "\n",
    "  * **Correctness:** Does the output match the expected answer?\n",
    "  * **Relevance:** Does the response address the input query?\n",
    "  * **Fluency:** Is the output grammatically correct and readable?\n",
    "  * **Completeness:** Does it cover all required aspects?\n",
    "\n",
    "**Manual Evaluation:**\n",
    "\n",
    "* Human reviewers read LLM outputs and assign scores based on predefined criteria.\n",
    "* Useful for nuanced assessments but **time-consuming**.\n",
    "\n",
    "**Automated Evaluation:**\n",
    "\n",
    "* Compare generated outputs with **gold standard references** using metrics like BLEU, ROUGE, or cosine similarity for embeddings.\n",
    "* Enables **scalable evaluation** of large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "**Metrics for Quality and Accuracy**\n",
    "\n",
    "| Metric                             | Description                                                  | Use Case                            |\n",
    "| ---------------------------------- | ------------------------------------------------------------ | ----------------------------------- |\n",
    "| **BLEU**                           | Measures n-gram overlap between generated and reference text | Translation tasks                   |\n",
    "| **ROUGE**                          | Measures recall-based overlap for summaries                  | Summarization tasks                 |\n",
    "| **Cosine Similarity (Embeddings)** | Measures semantic similarity between texts                   | Open-ended QA, retrieval evaluation |\n",
    "| **Exact Match (EM)**               | Checks if output exactly matches reference                   | Fact-based QA tasks                 |\n",
    "| **Human Score**                    | Subjective assessment of correctness, fluency, relevance     | Complex reasoning tasks             |\n",
    "\n",
    "---\n",
    "\n",
    "**Automated Evaluation Pipelines**\n",
    "\n",
    "* Automate evaluation using **LangChain components**:\n",
    "\n",
    "  1. Generate outputs using chains or agents\n",
    "  2. Compare outputs against reference answers\n",
    "  3. Compute metrics automatically\n",
    "  4. Log results for analysis or model improvement\n",
    "\n",
    "**Example: Automated QA Evaluation**\n",
    "\n",
    "```python\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Example data\n",
    "generated_answers = [\"LangChain is a framework for building LLM workflows.\"]\n",
    "reference_answers = [\"LangChain allows developers to create workflows using LLMs.\"]\n",
    "\n",
    "# Compute embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "gen_emb = model.encode(generated_answers)\n",
    "ref_emb = model.encode(reference_answers)\n",
    "\n",
    "# Compute similarity\n",
    "similarity_score = cosine_similarity(gen_emb, ref_emb)[0][0]\n",
    "print(f\"Semantic similarity score: {similarity_score:.2f}\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687c91b",
   "metadata": {},
   "source": [
    "## **Performance and Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709c650",
   "metadata": {},
   "source": [
    "**Speeding Up Embedding Queries**\n",
    "\n",
    "Embedding-based retrieval is often the **bottleneck** in RAG and similarity search pipelines. Optimizing embedding queries can drastically reduce latency.\n",
    "\n",
    "**Strategies:**\n",
    "\n",
    "1. **Use Efficient Vector Stores:**\n",
    "\n",
    "   * Tools like **FAISS, Chroma, Milvus, Pinecone** support fast approximate nearest neighbor (ANN) searches.\n",
    "   * Choose **index types** like IVF, HNSW, or PQ based on dataset size and query speed requirements.\n",
    "\n",
    "2. **Precompute Embeddings:**\n",
    "\n",
    "   * Store embeddings for all documents beforehand rather than generating them on-the-fly.\n",
    "   * Update embeddings only when new data is added.\n",
    "\n",
    "3. **Reduce Embedding Dimensionality:**\n",
    "\n",
    "   * Lower-dimensional embeddings reduce computation time and memory usage.\n",
    "   * Use models like **text-embedding-3-small** for smaller datasets or cost-sensitive applications.\n",
    "\n",
    "4. **Caching and Local Storage:**\n",
    "\n",
    "   * Cache frequently queried embeddings or results in memory or Redis to **avoid repeated computation**.\n",
    "\n",
    "**Example:** Precomputing and storing embeddings in Chroma\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import chromadb\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"precomputed_docs\")\n",
    "\n",
    "# Precompute and add embeddings\n",
    "for doc in documents:\n",
    "    vector = embedding_model.embed_query(doc.page_content)\n",
    "    collection.add(documents=[doc.page_content], embeddings=[vector])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Efficient Memory Management**\n",
    "\n",
    "LangChain supports **short-term and long-term memory**, but memory can become a bottleneck in large-scale applications.\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "1. **Chunking and Summarization:**\n",
    "\n",
    "   * Split long documents into smaller chunks to reduce token usage.\n",
    "   * Summarize intermediate content before storing in memory.\n",
    "\n",
    "2. **Memory Pruning:**\n",
    "\n",
    "   * Remove outdated or irrelevant conversation history in multi-turn dialogues.\n",
    "   * Keep only **recent or relevant context** to conserve memory.\n",
    "\n",
    "3. **Persistent vs. In-Memory Storage:**\n",
    "\n",
    "   * Store long-term memory in **persistent databases** like Chroma, Pinecone, or SQLite.\n",
    "   * Use in-memory structures for **active session memory** for speed.\n",
    "\n",
    "---\n",
    "\n",
    "**Batch Processing**\n",
    "\n",
    "Batch processing improves throughput and reduces latency when embedding multiple documents or queries.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Reduces API call overhead\n",
    "* Maximizes GPU/CPU utilization\n",
    "* Cost-efficient for large-scale LLM or embedding calls\n",
    "\n",
    "**Example: Batch Embeddings**\n",
    "\n",
    "```python\n",
    "batch_size = 32\n",
    "all_texts = [doc.page_content for doc in documents]\n",
    "batched_vectors = []\n",
    "\n",
    "for i in range(0, len(all_texts), batch_size):\n",
    "    batch = all_texts[i:i+batch_size]\n",
    "    vectors = embedding_model.embed_documents(batch)\n",
    "    batched_vectors.extend(vectors)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398091eb",
   "metadata": {},
   "source": [
    "## **Deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1b816",
   "metadata": {},
   "source": [
    "**API Deployment (FastAPI, Flask)**\n",
    "\n",
    "* Wrap chains and agents in a **web API** for interactive applications or external integrations.\n",
    "\n",
    "**Example: FastAPI Deployment**\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class Query(BaseModel):\n",
    "    question: str\n",
    "\n",
    "@app.post(\"/ask\")\n",
    "def ask_question(query: Query):\n",
    "    response = qa_chain.run(context=\"LangChain framework overview.\", question=query.question)\n",
    "    return {\"answer\": response}\n",
    "```\n",
    "\n",
    "* Supports **real-time user queries** with low latency.\n",
    "* Flask can be used similarly for smaller or legacy applications.\n",
    "\n",
    "---\n",
    "\n",
    "**Cloud Deployment (AWS, GCP, Azure)**\n",
    "\n",
    "* Host APIs and chains on cloud services for **scalability, high availability, and auto-scaling**.\n",
    "* Services include:\n",
    "\n",
    "  * **AWS:** EC2, Lambda, ECS, or SageMaker\n",
    "  * **GCP:** Cloud Run, Compute Engine, Vertex AI\n",
    "  * **Azure:** App Service, Azure Functions, AKS\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "* Use **autoscaling** for high-traffic scenarios.\n",
    "* Separate **compute-intensive tasks** like embedding generation to dedicated GPU instances.\n",
    "\n",
    "---\n",
    "\n",
    "**Docker and CI/CD Pipelines\n",
    "**\n",
    "* Containerize applications using **Docker** for portability and reproducibility.\n",
    "* Use **CI/CD pipelines** (GitHub Actions, GitLab CI, Jenkins) for automated testing, deployment, and versioning.\n",
    "\n",
    "**Example: Dockerfile for a LangChain API**\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY . .\n",
    "\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "* Ensures **consistent runtime environments** across development, staging, and production.\n",
    "\n",
    "---\n",
    "\n",
    "**Security and Best Practices**\n",
    "\n",
    "Ensuring security is critical when deploying LangChain applications, especially when handling **sensitive data or external APIs**.\n",
    "\n",
    "---\n",
    "\n",
    "**API Key Management**\n",
    "\n",
    "* Store keys securely using **environment variables, secrets managers, or encrypted storage**.\n",
    "* Avoid hardcoding API keys in code or repositories.\n",
    "\n",
    "**Example: Using Environment Variables**\n",
    "\n",
    "```python\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=api_key)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Data Privacy**\n",
    "* Ensure user data is **anonymized and encrypted** in storage and transit.\n",
    "* Avoid storing unnecessary personal data in memory or persistent databases.\n",
    "* Implement **access controls and logging** for auditability.\n",
    "\n",
    "---\n",
    "\n",
    "**Handling Sensitive Information**\n",
    "\n",
    "* Mask sensitive content before passing it to LLMs if required.\n",
    "* Use **role-based access control** for sensitive pipelines.\n",
    "* Employ **tokenization or pseudonymization** techniques for compliance with regulations like GDPR or HIPAA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80dad5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
